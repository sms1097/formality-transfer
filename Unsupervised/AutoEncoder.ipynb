{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "The autoencoder model failed to generate great speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import re \n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import workflow_manager as wm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50\n",
    "ENCODER_UNITS = 512\n",
    "DECODER_UNITS = 512\n",
    "ATTENTION_UNITS = 256\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '../Data'\n",
    "train, val, test, context = wm.load_and_tokenize(BASE_PATH)\n",
    "\n",
    "E_weights = wm.embedding_matrix(context['input_tokenizer'], \n",
    "                                context['input_vocab_size'], \n",
    "                                BASE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = wm.EncoderAuto(context['input_vocab_size'], EMBEDDING_DIM,\n",
    "                         ENCODER_UNITS, E_weights, 256)\n",
    "decoder = wm.DecoderAuto(context['target_vocab_size'], EMBEDDING_DIM,\n",
    "                     ATTENTION_UNITS, DECODER_UNITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, preds):\n",
    "    \"\"\"this is normal seq2seq loss\"\"\"\n",
    "\n",
    "    # caclulate loss\n",
    "    loss = static_loss(real, preds)\n",
    "    \n",
    "    # create padding mask \n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    \n",
    "    # apply mask\n",
    "    loss *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inpt, trgt, train=True):\n",
    "    loss = 0\n",
    "    target_tokenizer = context['target_tokenizer']\n",
    "    \n",
    "    # initialize seqs tensor\n",
    "    gen_seqs = tf.constant([target_tokenizer.word_index['<start>']] * BATCH_SIZE, dtype=tf.int64)\n",
    "    gen_seqs = tf.expand_dims(gen_seqs, axis=1)\n",
    "    \n",
    "    # This resets the hidden state of the LSTM for every epoch\n",
    "    init_state = [tf.zeros((BATCH_SIZE, ENCODER_UNITS)) for _ in range(4)]\n",
    "\n",
    "    ## Generate Sequences\n",
    "    enc_output = encoder(inpt, init_state)\n",
    "\n",
    "    # Get start token for every sequence in batch\n",
    "    dec_input = tf.expand_dims([target_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    for i in range(1, trgt.shape[1]):\n",
    "        # dec_hidden shape: (batch_size, decoder_units)\n",
    "        # dec_input shape: (batch_size, 1)\n",
    "        predictions = decoder(dec_input,\n",
    "                              enc_output)\n",
    "\n",
    "        loss += loss_function(trgt[:, i], predictions)\n",
    "        dec_input = tf.expand_dims(trgt[:, i], 1)\n",
    "        \n",
    "        # Need to hold onto seqs for discriminator\n",
    "        new_preds = tf.argmax(predictions, axis=1)\n",
    "        new_preds = tf.expand_dims(new_preds, axis=1)\n",
    "        gen_seqs = tf.concat([gen_seqs, new_preds], axis=1)\n",
    "\n",
    "    if not train:\n",
    "        return gen_seqs\n",
    "        \n",
    "    return gen_seqs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ein, eout = next(iter(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = predict(ein, eout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> i am that <OOV> <end> a by the leppard concert i not know that <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i <OOV> <end> a enjoy side to is a to be a <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i am to i <end> the <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i am be to be <end> you am not is <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i to are the <end> <OOV> <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i <OOV> <end> a ant farm and i of the own <end> that 1982 you are <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i you are you to do in <OOV> <OOV> is a know for <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i is in the <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i am wait the is the is i am not that is a the it <end> <OOV> <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i lol <end> am to i <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i you are the a is good <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i of the own <end> you <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i <OOV> <end> a good <end> <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i of a on the <end> <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i been it desire the you <OOV> <end> a the <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i am it <end> <end> i <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i is a deniro and i bowie <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i <OOV> know the <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i am to is good <end> of <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i i am not of the good <end> the is is is be a of the days <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i question is a i squares is <end> is to a <OOV> <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i are be a to be it good york of i am not know that is not a <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i is a me <OOV> and i are be it good <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i one the the <OOV> <end> a know the a <OOV> to <end> is <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i you am a <end> i the good <end> <end> of the <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i a <OOV> one <end> in the <OOV> <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i are be a to be it is the for the <OOV> <end> i is on the conan <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i is a <OOV> <end> plane <end> <end> is heard <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i time <end> else this is <end> <end> the <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i am to <OOV> of the <end> i are not to <end> <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i am that com a question <end> <end> i am that is not the media <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape',\n",
       " '<start> i are to <OOV> <end> and be taking them <end> <end> escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape escape']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context['target_tokenizer'].sequences_to_texts(x[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "This learns a sequence and then goes through usual GAN paradigm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inpt, trgt):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        gen_seqs, loss = predict(inpt, trgt)\n",
    "    \n",
    "    # Apply gradients \n",
    "    trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 1158.2526\n",
      "Time taken 0:01:00.694476\n",
      "\n",
      "Epoch 2 Loss 1155.3928\n",
      "Time taken 0:01:00.734925\n",
      "\n",
      "Epoch 3 Loss 1153.3864\n",
      "Time taken 0:01:00.760195\n",
      "\n",
      "Epoch 4 Loss 1151.5103\n",
      "Time taken 0:01:00.800789\n",
      "\n",
      "Epoch 5 Loss 1150.0364\n",
      "Time taken 0:01:00.840372\n",
      "\n",
      "Epoch 6 Loss 1148.4663\n",
      "Time taken 0:01:00.871697\n",
      "\n",
      "Epoch 7 Loss 1146.7633\n",
      "Time taken 0:01:00.847727\n",
      "\n",
      "Epoch 8 Loss 1145.5565\n",
      "Time taken 0:01:00.872212\n",
      "\n",
      "Epoch 9 Loss 1144.2554\n",
      "Time taken 0:01:00.887566\n",
      "\n",
      "Epoch 10 Loss 1142.7253\n",
      "Time taken 0:01:00.865393\n",
      "\n",
      "Epoch 11 Loss 1141.3679\n",
      "Time taken 0:01:00.877100\n",
      "\n",
      "Epoch 12 Loss 1140.3170\n",
      "Time taken 0:01:00.872470\n",
      "\n",
      "Epoch 13 Loss 1139.1207\n",
      "Time taken 0:01:00.956645\n",
      "\n",
      "Epoch 14 Loss 1138.1299\n",
      "Time taken 0:01:00.990489\n",
      "\n",
      "Epoch 15 Loss 1137.2744\n",
      "Time taken 0:01:00.953941\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d1a08681f44e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepoch_print\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Epoch {} | Generator Loss {:.4f} | Discriminator Loss {:.4f}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = datetime.now()\n",
    "    total_loss = 0\n",
    "\n",
    "    for inpt, trgt in train.take(context['steps_per_epoch']):\n",
    "        total_loss += train_step(inpt, trgt)\n",
    "    \n",
    "    epoch_print = 'Epoch {} | Generator Loss {:.4f} | Discriminator Loss {:.4f}'\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        total_loss / BATCH_SIZE))\n",
    "    print('Time taken {}\\n'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
