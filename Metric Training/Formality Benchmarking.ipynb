{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formality Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an implementation of the perplexity model used in <br>\n",
    "`E. Pavlick and J. Tetreault. An empirical analysis of formality in online communication.` <br>\n",
    "`Transactions of the Association for Computational Linguistics, 4:61â€“74, 2016.` <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Perplexity?\n",
    "Perplexity of a model is how well the model predicts the sample, or in this case the sequence it is fed. What we will do here for formality transfer is fit a model to the gigaword corpus (in this case just news articles, which are pretty formal and written by overly competent writers,) and then measure the perplexity of the sequences predicted by the model to see how close they are to being from the same distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we are going to create a Language Model that reperesents the distribution of the words of the corpus. Then, when we do style transfer later, we will be able to see how formal the outputs are, by seeing how well they match the distribution we are about to model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be trained on a subset of gigaword, specifically just the portion that is from news articles. This version of the data set is more accessible and much more affordable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tfds.load(\"Gigaword\", split=[\"train\"], as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "temp = np.vstack(tfds.as_numpy(data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean the data. Pretty basic, just going to decode (strings > bytes right now) and remove stop words, nothing super fancy here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(dirty_data):\n",
    "    clean_data = []\n",
    "    for row in dirty_data:\n",
    "        row = row[0].decode(\"utf-8\").lower()\n",
    "        \n",
    "        cleaned = filter(lambda word: word not in stopwords.words('english'), row.split(\" \"))\n",
    "        \n",
    "        clean_data.append(\" \".join(cleaned))\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = clean_data(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to create some train and test sets. In the end, I'm thinking I'll sleep at night knowing the model is accurate for ~10000 examples, but maybe I'll change my mind some day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cleaned-data.txt', 'w') as file:\n",
    "    for sequence in corpus:\n",
    "        file.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = np.random.choice(len(corpus), 10000)\n",
    "train_idx = list(set([i for i in range(len(corpus))]) - set(test_idx))\n",
    "\n",
    "train = [corpus[i] for i in train_idx]\n",
    "test = [corpus[i] for i in test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token = '<OOV>')\n",
    "tokenizer.fit_on_texts(train)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train)\n",
    "test_sequences = tokenizer.texts_to_sequences(test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to split the data into $n$-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_with_ngrams(data, n):\n",
    "    X, y = [], []\n",
    "    for sequence in data:\n",
    "        for ngram in zip(*[sequence[i:] for i in range(n)]):\n",
    "            X.append(np.array(ngram[:-1]))\n",
    "            y.append(ngram[-1])\n",
    "        \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = split_data_with_ngrams(train_sequences, 3)\n",
    "X_test, y_test = split_data_with_ngrams(test_sequences, 3)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, vocab_size+1)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, vocab_size+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now a model can be built!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size+1, 50, input_length=2),\n",
    "    tf.keras.layers.Dropout(0.2), \n",
    "    tf.keras.layers.LSTM(100, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(100),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(vocab_size+1, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to know how long this is taking to train, so I'll print every 100 epochs. Unfortunately, I can't do this wither the `verbose` argument, however I can write my own callback to print. Not quite as pretty, but it'll get the job done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetterVerboseCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: \", epoch)\n",
    "            print(\"loss: \", logs[\"loss\"])\n",
    "            print(\"accuracy\", logs[\"accuracy\"])\n",
    "            print(\"=\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          batch_size=256, \n",
    "          epochs=50, \n",
    "          verbose=0,\n",
    "          callbacks=[BetterVerboseCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
