{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Round Trip Translation for Data Augmentation\n",
    "The idea for backtranslation is that a round trip translation will create a more formal sentence. After the data is translated it will be run through the formality classifier to determine how much it matches the target corpus. If it scores high formality score (say about 85% out of softmax) then it will be added as an additional translation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '../../Data'  # on local is path to directory\n",
    "\n",
    "INFORMAL_PATH_TRAIN = '{}/Supervised Data/Entertainment_Music/S_Informal_EM_Train.txt'.format(BASE_PATH)\n",
    "INFORMAL_PATH_HOLDOUT = '{}/Supervised Data/Entertainment_Music/S_Informal_EM_ValTest.txt'.format(BASE_PATH)\n",
    "FORMAL_PATH_TRAIN = '{}/Supervised Data/Entertainment_Music/S_Formal_EM_Train.txt'.format(BASE_PATH)\n",
    "\n",
    "formal = open(FORMAL_PATH_TRAIN).read()\n",
    "informal = open(INFORMAL_PATH_TRAIN).read()\n",
    "informal_holdout = open(INFORMAL_PATH_HOLDOUT).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_corpus = [seq for seq in informal.split('\\n')]\n",
    "train_length = len(if_corpus)\n",
    "\n",
    "if_holdout = [seq for seq in informal_holdout.split('\\n')]\n",
    "\n",
    "f_corpus = [seq for seq in formal.split('\\n')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a workflow for getting through the google translation, however I kept running into a bug with API calls so I chose to break up the document into pieces and use google translate online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from googletrans import Translator\n",
    "rt = []  # round trip translations\n",
    "\n",
    "for seq in if_corpus:\n",
    "    t = Translator()\n",
    "    french = t.translate(seq, dest='fr')\n",
    "    english = t.translate(french, dest='en')\n",
    "    rt.append(english)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(if_corpus) // 2\n",
    "\n",
    "with open('first_half.txt', 'w') as f:\n",
    "    for seq in if_corpus[:length]:\n",
    "        f.write(seq + '\\n')\n",
    "\n",
    "with open('second_half.txt', 'w') as f:\n",
    "    for seq in if_corpus[length:]:\n",
    "        f.write(seq + '\\n')\n",
    "\n",
    "with open('informal_holdout.txt', 'w') as f:\n",
    "    for seq in if_holdout:\n",
    "        f.write(seq + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "with open(BASE_PATH + '/Supervised Data/FD Data/first_half.en.fr.fr.en.txt') as f:\n",
    "    seqs = f.readlines()\n",
    "    for seq in seqs[:]:\n",
    "        train.append(seq.strip('\\n'))\n",
    "\n",
    "with open(BASE_PATH + '/Supervised Data/FD Data/second_half.en.fr.fr.en.txt') as f:\n",
    "    seqs = f.readlines()\n",
    "    for seq in seqs[:]:\n",
    "        train.append(seq.strip('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to train and holdout\n",
    "Google Translate does "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_sequence(i=None):\n",
    "    if i is None:\n",
    "        i = random.randint(0, len(train)-1)\n",
    "    \n",
    "    print('Index:', i)\n",
    "    print('original train sequence:'.upper(), if_corpus[i])\n",
    "    print('round trip translation:'.upper(), train[i])\n",
    "    print('formal rewrite:'.upper(), f_corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 14702\n",
      "ORIGINAL TRAIN SEQUENCE: It stank so bad that I couldn't get into it.\n",
      "ROUND TRIP TRANSLATION: It smelled so bad I couldn't get in.\n",
      "FORMAL REWRITE: It sunk so quickly that I couldn't get into it.\n"
     ]
    }
   ],
   "source": [
    "get_random_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('informal_rt.txt', 'w') as f:\n",
    "    for seq in train:\n",
    "        f.write(seq + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
