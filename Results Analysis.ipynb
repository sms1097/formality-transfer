{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Choices\n",
    "- [Google-BLEU (GLEU)](https://web.science.mq.edu.au/~rdale/publications/papers/2007/gleu4ps2pdf.pdf): Alternative to BLEU that often aligns better with human judgements on MT tasks. GLEU measures precision and recall of all 1-4 grams and choses the minimum of the two. \n",
    "- [Character n-gram F-score (CHRF)](http://www.statmt.org/wmt15/pdf/WMT49.pdf): \n",
    "$$ (1 + \\beta^2) \\frac{CHRP \\times CHRR}{\\beta^2 CHRP + CHHRR} $$\n",
    "where $CHRP$ is the percentage of n-grams in the predicted sequence that are in the target sequence and $CHRR$ is the percentage of character n-grams in the predicted sequence that are also in the target sequence \n",
    "- [BiLingual Evaluation Understudy (BLEU)](https://www.aclweb.org/anthology/P02-1040.pdf):\n",
    "- Formality: The average predicted confidence each sequence is formal. Computed by neural network trained on separate labelled informal/formal corpus. Result is average softmax prediction for formal output. This model was trained to 83% accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.formality_classifier import FormalityClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from nltk.translate.chrf_score import corpus_chrf\n",
    "from nltk.translate.gleu_score import corpus_gleu\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "formality_classifier = FormalityClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_score(actual_file_path, results_file_path, num_groups=8, val=False):\n",
    "    # load data\n",
    "    actual = open(actual_file_path).read()\n",
    "    results = open(results_file_path).read()\n",
    "    \n",
    "    actual = [seq for seq in actual.split('\\n')]\n",
    "    results = [seq.replace('<start>', '').replace('<end>', '') for seq in results.split('\\n')]\n",
    "    \n",
    "    if val:\n",
    "        acutal = actual[:2000]\n",
    "        resutls = results[:2000]\n",
    "    \n",
    "    # split data into test groups\n",
    "    split_size = len(actual) // num_groups\n",
    "    actual_split = [actual[x:x+split_size] for x in range(0, len(actual), split_size)]\n",
    "    results_split = [results[x:x+split_size] for x in range(0, len(results), split_size)]\n",
    "    \n",
    "    # define smoothing funciton for BLEU\n",
    "    # method 5 averages counts for n-1, n, n+1 grams\n",
    "    s = SmoothingFunction().method5\n",
    "    \n",
    "    # loop through \n",
    "    formality, bleu, gleu, chrf = [], [], [], []\n",
    "    for a, r in zip(actual_split, results_split):\n",
    "        formality.append(formality_classifier.classify(a))\n",
    "        bleu.append(corpus_bleu(a, r, weights=(1,0,0,0)))\n",
    "        chrf.append(corpus_chrf(a, r))\n",
    "        gleu.append(corpus_gleu(a, r))\n",
    "    \n",
    "    df = pd.DataFrame(list(zip(bleu, gleu, chrf, formality)),\n",
    "                      columns=['BLEU', 'GLEU', 'CHRF', 'FORMALITY'])\n",
    "    \n",
    "    print('BLEU: {:4f} | CHRF: {:4f} | FORMALITY: {:4f} | GLEU: {:4f}'.format(np.mean(bleu), \n",
    "                                                                              np.mean(chrf), \n",
    "                                                                              np.mean(formality),\n",
    "                                                                              np.mean(gleu)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = 'Data/Results/'\n",
    "actual = 'Data/Supervised Data/Entertainment_Music/S_Formal_EM_ValTest.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from GYAFC Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gyafc_results = 'Data/GYAFC_Corpus/Entertainment_Music/model_outputs/formal.nmt_baseline'\n",
    "gyafc_actual = 'Data/GYAFC_Corpus/Entertainment_Music/test/formal.ref0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/sean/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/sean/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.306912 | CHRF: 0.563394 | FORMALITY: 0.676480 | GLEU: 0.004694\n"
     ]
    }
   ],
   "source": [
    "gyafc_df = load_and_score(gyafc_results, gyafc_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Encoder Decoder Custom\n",
    "The vanilla encoder decoder feeds the sequences into encoder to learn a latent representation. The decoder then iterates through the original sequence and uses the latent representation to predict a next word. This model was trained for 30 epochs on 25,0000 sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.193423 | CHRF: 0.121051 | FORMALITY: 0.995549 | GLEU: 0.004617\n"
     ]
    }
   ],
   "source": [
    "ved_df = load_and_score(BASE_PATH + 'vanilla_encoder_decoder_results_custom.txt', actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Transformer Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.065263 | CHRF: 0.065662 | FORMALITY: 0.558764 | GLEU: 0.004617\n"
     ]
    }
   ],
   "source": [
    "ct_df = load_and_score(BASE_PATH + 'Custom_Transformer_Results.txt', actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bahdanau Attention\n",
    "```\n",
    "Informal:  <start> pretty woman but i cant remember who sings it .  <end>\n",
    "Formal:  <start> The song is called Pretty Woman , but I cannot remember who sings it .  <end>\n",
    "Predicted:  <start> i believe she is a woman i can not remember who sings the song <end> \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.258770 | CHRF: 0.243385 | FORMALITY: 0.698479 | GLEU: 0.004617\n"
     ]
    }
   ],
   "source": [
    "ba_df = load_and_score(BASE_PATH + 'Bahdanau_Attention_Results_Custom.txt', actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONMT Transformer\n",
    "ONMT transformer was trained on the first 2000 sequences of the test set, and the remaining sequences were used as validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.279566 | CHRF: 0.385392 | FORMALITY: 0.644124 | GLEU: 0.004531\n"
     ]
    }
   ],
   "source": [
    "onmt_T_df = load_and_score(BASE_PATH + 'onmt_transformer_output.txt', actual, val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
