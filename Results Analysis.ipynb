{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Choices\n",
    "- [Google-BLEU (GLEU)](https://web.science.mq.edu.au/~rdale/publications/papers/2007/gleu4ps2pdf.pdf): Alternative to BLEU that often aligns better with human judgements on MT tasks. GLEU measures precision and recall of all 1-4 grams and choses the minimum of the two. \n",
    "- [Character n-gram F-score (CHRF)](http://www.statmt.org/wmt15/pdf/WMT49.pdf): \n",
    "$$ (1 + \\beta^2) \\frac{CHRP \\times CHRR}{\\beta^2 CHRP + CHHRR} $$\n",
    "where $CHRP$ is the percentage of n-grams in the predicted sequence that are in the target sequence and $CHRR$ is the percentage of character n-grams in the predicted sequence that are also in the target sequence \n",
    "- [BiLingual Evaluation Understudy (BLEU)](https://www.aclweb.org/anthology/P02-1040.pdf):\n",
    "- Formality: The average predicted confidence each sequence is formal. Computed by neural network trained on separate labelled informal/formal corpus. Result is average softmax prediction for formal output. This model was trained to 83% accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.formality_classifier import FormalityClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from nltk.translate.chrf_score import corpus_chrf\n",
    "from nltk.translate.gleu_score import corpus_gleu\n",
    "import more_itertools as mit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "formality_classifier = FormalityClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_score(results_file_path, actual_file_path, num_groups=8, val=False):\n",
    "    def replace(seq):\n",
    "        if seq is not None:\n",
    "            return seq.replace('<start>', '').replace('<end>', '')\n",
    "        else:\n",
    "            return ' '\n",
    "    # load data\n",
    "    actual = open(actual_file_path).read()\n",
    "    results = open(results_file_path).read()\n",
    "\n",
    "    actual = [replace(seq) for seq in actual.split('\\n')]\n",
    "    results = [replace(seq) for seq in results.split('\\n')]\n",
    "\n",
    "    if val:\n",
    "        actual = actual[:2000]\n",
    "        results = results[:2000]\n",
    "\n",
    "\n",
    "    # split data into test groups\n",
    "    split_size = len(actual) // num_groups\n",
    "    actual_split = [actual[x:x+split_size] for x in range(0, len(actual), split_size)]\n",
    "    results_split = [results[x:x+split_size] for x in range(0, len(results), split_size)]\n",
    "    \n",
    "    s = SmoothingFunction().method5\n",
    "\n",
    "    # loop through \n",
    "    formality, bleu, gleu, chrf = [], [], [], []\n",
    "    for a, r in zip(actual_split, results_split):\n",
    "        formality.append(formality_classifier.classify(r))\n",
    "        bleu.append(corpus_bleu(a, r, smoothing_function=s))\n",
    "        chrf.append(corpus_chrf(a, r))\n",
    "        gleu.append(corpus_gleu(a, r))\n",
    "\n",
    "    df = pd.DataFrame(list(zip(bleu, gleu, chrf, formality)),\n",
    "                      columns=['BLEU', 'GLEU', 'CHRF', 'FORMALITY'])\n",
    "\n",
    "    print('BLEU: {:4f} | CHRF: {:4f} | FORMALITY: {:4f} | GLEU: {:4f}'.format(np.mean(bleu), \n",
    "                                                                              np.mean(chrf), \n",
    "                                                                              np.mean(formality),\n",
    "                                                                              np.mean(gleu)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = 'Data/Results/'\n",
    "actual = 'Data/Supervised Data/Entertainment_Music/S_Formal_EM_ValTest.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from GYAFC Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gyafc_results = 'Data/GYAFC_Corpus/Entertainment_Music/model_outputs/formal.nmt_baseline'\n",
    "gyafc_actual = 'Data/GYAFC_Corpus/Entertainment_Music/test/formal.ref0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.109758 | CHRF: 0.499192 | FORMALITY: 0.676480 | GLEU: 0.005461\n"
     ]
    }
   ],
   "source": [
    "gyafc_df = load_and_score(gyafc_results, gyafc_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Encoder Decoder Custom\n",
    "The vanilla encoder decoder feeds the sequences into encoder to learn a latent representation. The decoder then iterates through the original sequence and uses the latent representation to predict a next word. This model was trained for 30 epochs on 25,0000 sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.122410 | CHRF: 0.041665 | FORMALITY: 0.980703 | GLEU: 0.017241\n"
     ]
    }
   ],
   "source": [
    "ved_df = load_and_score(BASE_PATH + 'vanilla_encoder_decoder_results_custom.txt', actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bahdanau Attention\n",
    "```\n",
    "Informal:  <start> pretty woman but i cant remember who sings it .  <end>\n",
    "Formal:  <start> The song is called Pretty Woman , but I cannot remember who sings it .  <end>\n",
    "Predicted:  <start> i believe she is a woman i can not remember who sings the song <end> \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.094351 | CHRF: 0.270998 | FORMALITY: 0.696809 | GLEU: 0.004408\n"
     ]
    }
   ],
   "source": [
    "ba_df = load_and_score(BASE_PATH + 'Bahdanau_Attention_Results_Custom.txt', actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONMT Transformer\n",
    "ONMT transformer was trained on the first 2000 sequences of the test set, and the remaining sequences were used as validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.103317 | CHRF: 0.348424 | FORMALITY: 0.644124 | GLEU: 0.004962\n"
     ]
    }
   ],
   "source": [
    "onmt_T_df = load_and_score(BASE_PATH + 'onmt_transformer_output.txt', actual, val=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF POS Model\n",
    "The CRF POS was a sequence2sequence model trained using [parallel encodings](https://arxiv.org/pdf/1804.09849.pdfhttps://arxiv.org/pdf/1804.09849.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.104216 | CHRF: 0.075835 | FORMALITY: 0.867475 | GLEU: 0.008274\n"
     ]
    }
   ],
   "source": [
    "crf_pos_df = load_and_score(BASE_PATH + 'crf_pos_seq2seq_predictions.txt', actual, val=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer with Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.105755 | CHRF: 0.127470 | FORMALITY: 0.783835 | GLEU: 0.006438\n"
     ]
    }
   ],
   "source": [
    "rule_trans = load_and_score(BASE_PATH + 'rule_based_transformer.txt', actual, val=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF Pos Concat with Global Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.070510 | CHRF: 0.044980 | FORMALITY: 0.541870 | GLEU: 0.002499\n"
     ]
    }
   ],
   "source": [
    "pos_concat = load_and_score(BASE_PATH + 'CRF_POS_Concat.txt', actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule Concat with Global Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.077328 | CHRF: 0.037900 | FORMALITY: 0.571993 | GLEU: 0.005349\n"
     ]
    }
   ],
   "source": [
    "rule_concat = load_and_score(BASE_PATH + 'Rule_Concat.txt', actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
