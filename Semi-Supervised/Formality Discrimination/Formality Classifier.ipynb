{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Formality Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDMinZFhZPoy"
      },
      "source": [
        "# Formality Classifier\n",
        "This is going to be used to classify whether a sentence should be included in the informal or formal corpus. This will work by selecting the probability of the sentence belonging to the corpus, and if the score exceeds a threshold it will be included. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZpo0DbmMOT_"
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "import re \n",
        "import os\n",
        "import pickle\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaBecDtGZPoz"
      },
      "source": [
        "### Static Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2WlCl45ZPoz"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "EMBEDDING_DIM = 200"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPJWD7o4ZPoz"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDs7s6MIZgs7",
        "outputId": "0020ebd1-5686-47a8-aa1d-83984533d7fe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzSYxc4yMOT_"
      },
      "source": [
        "# BASE_PATH = '../../Data'  # on local is path to directory\n",
        "BASE_PATH = '/content/drive/MyDrive/Data/Data'\n",
        "\n",
        "FORMAL_PATH_TRAIN = '{}/Supervised Data/Family_Relationships/S_Formal_FR_train.txt'.format(BASE_PATH)\n",
        "INFORMAL_PATH_TRAIN = '{}/Supervised Data/Family_Relationships/S_Informal_FR_train.txt'.format(BASE_PATH)\n",
        "\n",
        "FORMAL_PATH_HOLDOUT = '{}/Supervised Data/Family_Relationships/S_Formal_FR_ValTest.txt'.format(BASE_PATH)\n",
        "INFORMAL_PATH_HOLDOUT = '{}/Supervised Data/Family_Relationships/S_Informal_FR_ValTest.txt'.format(BASE_PATH)\n",
        "\n",
        "EMBEDDING_PATH = '{}/glove.6B.200d.txt'.format(BASE_PATH)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6EaDkEtMOUA"
      },
      "source": [
        "formal = open(FORMAL_PATH_TRAIN).read()\n",
        "informal = open(INFORMAL_PATH_TRAIN).read()\n",
        "\n",
        "formal_holdout = open(FORMAL_PATH_HOLDOUT).read()\n",
        "informal_holdout = open(INFORMAL_PATH_HOLDOUT).read()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu1glafMZPoz"
      },
      "source": [
        "### Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fenTZWMxMOUA"
      },
      "source": [
        "def process_sequence(seq):\n",
        "    \"\"\"This inserts a space in between the last word and a period\"\"\"\n",
        "    s = re.sub('([.,!?()])', r' \\1 ', seq)\n",
        "    s = re.sub('\\s{2,}', ' ', s)\n",
        "    \n",
        "    return '<start> ' + s + ' <end>'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_pLPgB0MOUA"
      },
      "source": [
        "f_corpus = [process_sequence(seq) for seq in formal.split('\\n')]\n",
        "if_corpus = [process_sequence(seq) for seq in informal.split('\\n')]\n",
        "\n",
        "f_holdout = [process_sequence(seq) for seq in formal_holdout.split('\\n')]\n",
        "if_holdout = [process_sequence(seq) for seq in informal_holdout.split('\\n')]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31_t-0y5ZPoz"
      },
      "source": [
        "input_corpus = f_corpus.copy()\n",
        "input_corpus.extend(if_corpus)\n",
        "\n",
        "input_labels = [True for _ in range(len(f_corpus))]\n",
        "input_labels.extend([False for _ in range(len(if_corpus))])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu-xm1fLZPoz"
      },
      "source": [
        "holdout_corpus = f_holdout.copy()\n",
        "holdout_corpus.extend(if_holdout)\n",
        "\n",
        "holdout_labels = [True for _ in range(len(f_holdout))]\n",
        "holdout_labels.extend([False for _ in range(len(if_holdout))])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Rmi9pDx-BCr",
        "outputId": "8ce70fd2-1bac-408b-921b-e8bbe7c30917",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "i = 26000\n",
        "print(input_corpus[i])\n",
        "print(input_labels[i])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> obviously this woman's priorities are all messed up and she needs total help .  <end>\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYOFA9fRZPoz"
      },
      "source": [
        "### Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czog7VXRMOUA"
      },
      "source": [
        "def tokenize(corpus, tokenizer=None, maxlen=None):\n",
        "    \"\"\" Tokenize data and pad sequences \"\"\"\n",
        "    if not tokenizer: \n",
        "        tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', \n",
        "                              oov_token='<OOV>')\n",
        "        tokenizer.fit_on_texts(corpus)\n",
        "    \n",
        "    seqs = tokenizer.texts_to_sequences(corpus)\n",
        "    padded_seqs = pad_sequences(seqs, padding='post', maxlen=maxlen)\n",
        "\n",
        "    return padded_seqs, tokenizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPM9wDXhZPoz"
      },
      "source": [
        "train_set, tokenizer = tokenize(input_corpus)\n",
        "test_set, _ = tokenize(holdout_corpus, tokenizer)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2t-kmVr90sw",
        "outputId": "fe6b81c6-8e58-4197-9efa-fd3f99cab4ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_set[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  2,   6, 349,   5, 124,   9,  74,  63,  35,   3,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_VM2_4LZPoz"
      },
      "source": [
        "### Setup TF dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJpBO_F9MOUA"
      },
      "source": [
        "buffer_size = len(train_set)\n",
        "steps_per_epoch = len(train_set) // BATCH_SIZE\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "train = tf.data.Dataset.from_tensor_slices((train_set, input_labels)).shuffle(buffer_size)\n",
        "train = train.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "test = tf.data.Dataset.from_tensor_slices((test_set, holdout_labels))\n",
        "test = test.batch(BATCH_SIZE)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT6Z0lzkZPoz"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(train))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4Bf8jXRZPoz"
      },
      "source": [
        "### Load Embedding Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enju-_z_p9u7"
      },
      "source": [
        "def embedding_matrix(tokenizer, vocab_size, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(EMBEDDING_PATH) as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "\n",
        "    embeddings_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in tokenizer.word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embeddings_matrix[i] = embedding_vector\n",
        "\n",
        "    return embeddings_matrix"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YZxhplsZPoz"
      },
      "source": [
        "E = embedding_matrix(tokenizer, vocab_size, EMBEDDING_DIM)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR_aCG_3ZPoz"
      },
      "source": [
        "## Declare Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JfJYDkuZPoz"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, EMBEDDING_DIM, weights=[E], mask_zero=True), \n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(1024, return_sequences=True),\n",
        "    tf.keras.layers.LSTM(1024),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-44fwfcZPo0"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZHaJfIFZPo0",
        "outputId": "c4ce95ad-939b-4af8-9805-cb1493a243b2"
      },
      "source": [
        "history = model.fit(train, epochs=10)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.5068 - accuracy: 0.7376\n",
            "Epoch 2/10\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.4267 - accuracy: 0.7925\n",
            "Epoch 3/10\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.3904 - accuracy: 0.8114\n",
            "Epoch 4/10\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.3626 - accuracy: 0.8252\n",
            "Epoch 5/10\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.3406 - accuracy: 0.8358\n",
            "Epoch 6/10\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.3173 - accuracy: 0.8456\n",
            "Epoch 7/10\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.2963 - accuracy: 0.8544\n",
            "Epoch 8/10\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.2765 - accuracy: 0.8652\n",
            "Epoch 9/10\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.2567 - accuracy: 0.8730\n",
            "Epoch 10/10\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.2378 - accuracy: 0.8838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPoqEn5ZZPo0",
        "outputId": "633032f2-67c2-4e39-e1ec-1c2bc394954c"
      },
      "source": [
        "model.evaluate(test)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 1s 15ms/step - loss: 0.5985 - accuracy: 0.7896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5984866619110107, 0.7896341681480408]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7UwkugTCpy-"
      },
      "source": [
        "Going to find the following data set \n",
        "$$ T_{avg} = \\{(s_i, s_i^\\prime)|P_+(s_i^\\prime) - P_+(s_i) > \\sigma \\}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1onymzGYCplF",
        "outputId": "54fc3e7e-18cd-4ccc-83b0-af62ee05638e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.predict(test)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.49983445, 0.5001656 ],\n",
              "       [0.4999894 , 0.5000106 ],\n",
              "       [0.5001057 , 0.49989432],\n",
              "       ...,\n",
              "       [0.500086  , 0.49991402],\n",
              "       [0.5000835 , 0.49991652],\n",
              "       [0.50109226, 0.49890772]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5WsWSRVDCPQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}