{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Formality Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDMinZFhZPoy"
      },
      "source": [
        "# Formality Classifier\n",
        "This is going to be used to classify whether a sentence should be included in the informal or formal corpus. This will work by selecting the probability of the sentence belonging to the corpus, and if the score exceeds a threshold it will be included. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZpo0DbmMOT_"
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "import re \n",
        "import os\n",
        "import pickle\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaBecDtGZPoz"
      },
      "source": [
        "### Static Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2WlCl45ZPoz"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "EMBEDDING_DIM = 200"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPJWD7o4ZPoz"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDs7s6MIZgs7",
        "outputId": "3f1927c2-34f7-46ae-def4-33422fdedd2b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzSYxc4yMOT_"
      },
      "source": [
        "# BASE_PATH = '../../Data'  # on local is path to directory\n",
        "BASE_PATH = '/content/drive/MyDrive/Data/Data'\n",
        "\n",
        "FORMAL_PATH_TRAIN = '{}/Supervised Data/Family_Relationships/S_Formal_FR_train.txt'.format(BASE_PATH)\n",
        "INFORMAL_PATH_TRAIN = '{}/Supervised Data/Family_Relationships/S_Informal_FR_train.txt'.format(BASE_PATH)\n",
        "\n",
        "FORMAL_PATH_HOLDOUT = '{}/Supervised Data/Family_Relationships/S_Formal_FR_ValTest.txt'.format(BASE_PATH)\n",
        "INFORMAL_PATH_HOLDOUT = '{}/Supervised Data/Family_Relationships/S_Informal_FR_ValTest.txt'.format(BASE_PATH)\n",
        "\n",
        "EMBEDDING_PATH = '{}/glove.6B.200d.txt'.format(BASE_PATH)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6EaDkEtMOUA"
      },
      "source": [
        "formal = open(FORMAL_PATH_TRAIN).read()\n",
        "informal = open(INFORMAL_PATH_TRAIN).read()\n",
        "\n",
        "formal_holdout = open(FORMAL_PATH_HOLDOUT).read()\n",
        "informal_holdout = open(INFORMAL_PATH_HOLDOUT).read()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu1glafMZPoz"
      },
      "source": [
        "### Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fenTZWMxMOUA"
      },
      "source": [
        "def process_sequence(seq):\n",
        "    \"\"\"This inserts a space in between the last word and a period\"\"\"\n",
        "    s = re.sub('([.,!?()])', r' \\1 ', seq)\n",
        "    s = re.sub('\\s{2,}', ' ', s)\n",
        "    \n",
        "    return '<start> ' + s + ' <end>'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_pLPgB0MOUA",
        "outputId": "4409cff0-b255-45c1-a368-3b6c5f0f98a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "f_corpus = [process_sequence(seq) for seq in formal.split('\\n')]\n",
        "if_corpus = [process_sequence(seq) for seq in informal.split('\\n')]\n",
        "\n",
        "f_holdout = [process_sequence(seq) for seq in formal_holdout.split('\\n')]\n",
        "if_holdout = [process_sequence(seq) for seq in informal_holdout.split('\\n')]\n",
        "\n",
        "print(\"Length of holdout set raw is\", len(f_holdout))\n",
        "\n",
        "f_val = f_holdout[:968]\n",
        "if_val = if_holdout[:968]\n",
        "\n",
        "if_holdout = if_holdout[968:]\n",
        "f_holdout = f_holdout[968:]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of holdout set is 1968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HDoSZq0gELy"
      },
      "source": [
        "def split_corpora(formal, informal):\n",
        "    corpus = formal.copy()\n",
        "    corpus.extend(informal)\n",
        "\n",
        "    corpus_labels = [True for _ in range(len(formal))]\n",
        "    corpus_labels.extend([False for _ in range(len(informal))])\n",
        "\n",
        "    return corpus, corpus_labels"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weeffZBfgdZv"
      },
      "source": [
        "input_corpus, input_labels = split_corpora(f_corpus, if_corpus)\n",
        "holdout_corpus, holdout_labels = split_corpora(f_holdout, if_holdout)\n",
        "val_corpus, val_labels = split_corpora(f_val, if_val)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYOFA9fRZPoz"
      },
      "source": [
        "### Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czog7VXRMOUA"
      },
      "source": [
        "def tokenize(corpus, tokenizer=None, maxlen=None):\n",
        "    \"\"\" Tokenize data and pad sequences \"\"\"\n",
        "    if not tokenizer: \n",
        "        tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', \n",
        "                              oov_token='<OOV>')\n",
        "        tokenizer.fit_on_texts(corpus)\n",
        "    \n",
        "    seqs = tokenizer.texts_to_sequences(corpus)\n",
        "    padded_seqs = pad_sequences(seqs, padding='post', maxlen=maxlen)\n",
        "\n",
        "    return padded_seqs, tokenizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPM9wDXhZPoz"
      },
      "source": [
        "train_set, tokenizer = tokenize(input_corpus)\n",
        "val_set, _ = tokenize(val_corpus, tokenizer)\n",
        "test_set, _ = tokenize(holdout_corpus, tokenizer)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_VM2_4LZPoz"
      },
      "source": [
        "### Setup TF dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJpBO_F9MOUA"
      },
      "source": [
        "buffer_size = len(train_set)\n",
        "steps_per_epoch = len(train_set) // BATCH_SIZE\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "train = tf.data.Dataset.from_tensor_slices((train_set, input_labels)).shuffle(buffer_size)\n",
        "train = train.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "test = tf.data.Dataset.from_tensor_slices((test_set, holdout_labels))\n",
        "test = test.batch(BATCH_SIZE)\n",
        "\n",
        "val = tf.data.Dataset.from_tensor_slices((val_set, val_labels))\n",
        "val = val.batch(BATCH_SIZE)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT6Z0lzkZPoz"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(train))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4Bf8jXRZPoz"
      },
      "source": [
        "### Load Embedding Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enju-_z_p9u7"
      },
      "source": [
        "def embedding_matrix(tokenizer, vocab_size, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(EMBEDDING_PATH) as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "\n",
        "    embeddings_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in tokenizer.word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embeddings_matrix[i] = embedding_vector\n",
        "\n",
        "    return embeddings_matrix"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YZxhplsZPoz"
      },
      "source": [
        "E = embedding_matrix(tokenizer, vocab_size, EMBEDDING_DIM)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR_aCG_3ZPoz"
      },
      "source": [
        "## Declare Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JfJYDkuZPoz"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, EMBEDDING_DIM, weights=[E], mask_zero=True), \n",
        "    tf.keras.layers.LSTM(512, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(512, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(512),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL12HzFup4Uu"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, EMBEDDING_DIM, weights=[E], mask_zero=True), \n",
        "    tf.keras.layers.Conv1D(32, 5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-44fwfcZPo0"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZHaJfIFZPo0",
        "outputId": "91ce1d89-beaf-4e58-f8f0-0119ff0d32d2"
      },
      "source": [
        "history = model.fit(train, validation_data=val, epochs=5)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "781/781 [==============================] - 43s 55ms/step - loss: 0.4960 - accuracy: 0.7447 - val_loss: 0.4633 - val_accuracy: 0.7645\n",
            "Epoch 2/5\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.4208 - accuracy: 0.7937 - val_loss: 0.4426 - val_accuracy: 0.7676\n",
            "Epoch 3/5\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.3830 - accuracy: 0.8145 - val_loss: 0.4535 - val_accuracy: 0.7634\n",
            "Epoch 4/5\n",
            "781/781 [==============================] - 39s 51ms/step - loss: 0.3490 - accuracy: 0.8313 - val_loss: 0.4499 - val_accuracy: 0.7774\n",
            "Epoch 5/5\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.3207 - accuracy: 0.8449 - val_loss: 0.4878 - val_accuracy: 0.7732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPoqEn5ZZPo0"
      },
      "source": [
        "model.evaluate(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7UwkugTCpy-"
      },
      "source": [
        "Going to find the following data set \n",
        "$$ T_{avg} = \\{(s_i, s_i^\\prime)|P_+(s_i^\\prime) - P_+(s_i) > \\sigma \\}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1onymzGYCplF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54fc3e7e-18cd-4ccc-83b0-af62ee05638e"
      },
      "source": [
        "model.predict(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.49983445, 0.5001656 ],\n",
              "       [0.4999894 , 0.5000106 ],\n",
              "       [0.5001057 , 0.49989432],\n",
              "       ...,\n",
              "       [0.500086  , 0.49991402],\n",
              "       [0.5000835 , 0.49991652],\n",
              "       [0.50109226, 0.49890772]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5WsWSRVDCPQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}