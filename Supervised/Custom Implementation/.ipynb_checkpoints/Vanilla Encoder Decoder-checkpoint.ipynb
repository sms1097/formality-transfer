{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Attention Model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WZnAymJMOT-"
      },
      "source": [
        "# Vanilla Encoder-Decoder\n",
        "This is a basic encoder decoder model with no attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZpo0DbmMOT_"
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "import re \n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzyN1cVWeXkp"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIh8TGdFMOT_"
      },
      "source": [
        "### Declare Static Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLWD_vDUMUbK",
        "outputId": "a1fe579f-3e7d-4966-85e1-af3936de201b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiCo7jwJMOT_"
      },
      "source": [
        "These parameters are mostly stolen from the Google Paper, except for embedding dim which is determined from GloVE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgjKj15QMOT_"
      },
      "source": [
        "EMBEDDING_DIM = 200\n",
        "ENCODER_UNITS = 1024\n",
        "DECODER_UNITS = 1024\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9sTDg2lMOT_"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzSYxc4yMOT_"
      },
      "source": [
        "BASE_PATH = '/content/drive/MyDrive/Data/Data'  # on local is path to directory\n",
        "# BASE_PATH = '../../Data'\n",
        "\n",
        "FORMAL_PATH_TRAIN = '{}/Supervised Data/Entertainment_Music/S_Formal_EM_Train.txt'.format(BASE_PATH)\n",
        "INFORMAL_PATH_TRAIN = '{}/Supervised Data/Entertainment_Music/S_Informal_EM_Train.txt'.format(BASE_PATH)\n",
        "\n",
        "FORMAL_PATH_HOLDOUT = '{}/Supervised Data/Entertainment_Music/S_Formal_EM_ValTest.txt'.format(BASE_PATH)\n",
        "INFORMAL_PATH_HOLDOUT = '{}/Supervised Data/Entertainment_Music/S_Informal_EM_ValTest.txt'.format(BASE_PATH)\n",
        "\n",
        "EMBEDDING_PATH = '{}/glove.6B.200d.txt'.format(BASE_PATH)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6EaDkEtMOUA"
      },
      "source": [
        "formal = open(FORMAL_PATH_TRAIN).read()\n",
        "informal = open(INFORMAL_PATH_TRAIN).read()\n",
        "\n",
        "formal_holdout = open(FORMAL_PATH_HOLDOUT).read()\n",
        "informal_holdout = open(INFORMAL_PATH_HOLDOUT).read()"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fenTZWMxMOUA"
      },
      "source": [
        "def process_sequence(seq):\n",
        "    \"\"\"This inserts a space in between the last word and a period\"\"\"\n",
        "    s = re.sub('([.,!?()])', r' \\1 ', seq)\n",
        "    s = re.sub('\\s{2,}', ' ', s)\n",
        "    s = re.sub(r\"[^a-zA-Z?.!,Â¿]+\", \" \", s)\n",
        "    \n",
        "    return '<start> ' + s + ' <end>'"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_pLPgB0MOUA"
      },
      "source": [
        "f_corpus = [process_sequence(seq) for seq in formal.split('\\n')]\n",
        "if_corpus = [process_sequence(seq) for seq in informal.split('\\n')]\n",
        "\n",
        "f_holdout = [process_sequence(seq) for seq in formal_holdout.split('\\n')]\n",
        "if_holdout = [process_sequence(seq) for seq in informal_holdout.split('\\n')]"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuet6JWVMOUA"
      },
      "source": [
        "### Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czog7VXRMOUA"
      },
      "source": [
        "def tokenize(corpus, tokenizer=None, maxlen=None):\n",
        "    \"\"\" Tokenize data and pad sequences \"\"\"\n",
        "    if not tokenizer: \n",
        "        tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', \n",
        "                              oov_token='<OOV>')\n",
        "        tokenizer.fit_on_texts(corpus)\n",
        "    \n",
        "    seqs = tokenizer.texts_to_sequences(corpus)\n",
        "    padded_seqs = pad_sequences(seqs, padding='post', maxlen=maxlen)\n",
        "\n",
        "    return padded_seqs, tokenizer"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8gCiXWAMOUA"
      },
      "source": [
        "input_train, input_tokenizer = tokenize(if_corpus)\n",
        "target_train, target_tokenizer = tokenize(f_corpus)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROQQKO8uMOUA"
      },
      "source": [
        "input_test, _ = tokenize(if_holdout, input_tokenizer, 32)\n",
        "target_test, _ = tokenize(f_holdout, target_tokenizer)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJpBO_F9MOUA"
      },
      "source": [
        "buffer_size = len(input_train)\n",
        "steps_per_epoch = len(input_train) // BATCH_SIZE\n",
        "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
        "\n",
        "train = tf.data.Dataset.from_tensor_slices((input_train, target_train)).shuffle(buffer_size)\n",
        "train = train.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "test = tf.data.Dataset.from_tensor_slices((input_test, target_test)).batch(1)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua_l1fZEMOUA"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(train))"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpGaTdQN0nKP"
      },
      "source": [
        "test_in_batch, test_out_batch = next(iter(test))"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSCRTB5PjmvD"
      },
      "source": [
        "# Setup Embedding Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enju-_z_p9u7"
      },
      "source": [
        "def embedding_matrix(tokenizer, vocab_size, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(EMBEDDING_PATH) as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "\n",
        "    embeddings_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in tokenizer.word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embeddings_matrix[i] = embedding_vector\n",
        "\n",
        "    return embeddings_matrix"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovQqc3ibqVj6"
      },
      "source": [
        "enc_E_mat = embedding_matrix(input_tokenizer, input_vocab_size, EMBEDDING_DIM)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pv7RI8NMOUA"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dVMrge8kBd3"
      },
      "source": [
        "Using one bidirectional LSTMs because that was reported to get almost as good performance as 2 LSTMs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiW3IKWKMOUA"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size,\n",
        "                 weight_matrix):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.encoder_units = encoder_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, \n",
        "                                                   embedding_dim,\n",
        "                                                   weights=[weight_matrix])\n",
        "        self.lstm_1 = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(\n",
        "                self.encoder_units,\n",
        "                return_sequences=True,\n",
        "                return_state=False\n",
        "            )\n",
        "        )\n",
        "        self.lstm_2 = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(\n",
        "                self.encoder_units,\n",
        "                return_sequences=True,\n",
        "                return_state=False\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def call(self, x, hidden_state):\n",
        "        \"\"\"Shove into latent space\"\"\"\n",
        "        # x shape: (batch_size x max_length x embedding_dim)\n",
        "        output = self.embedding(x)\n",
        "\n",
        "        # output shape: (batch_size x max_length x 2 * encoder_units)\n",
        "        # h_f, h_b shapes: (batch_size x encoder_units)\n",
        "        output = self.lstm_1(output)\n",
        "\n",
        "        output = self.lstm_2(output)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjpvfT3XMOUA"
      },
      "source": [
        "encoder = Encoder(input_vocab_size, EMBEDDING_DIM, ENCODER_UNITS, \n",
        "                  BATCH_SIZE, enc_E_mat)\n",
        "\n",
        "init_state = [tf.zeros((BATCH_SIZE, ENCODER_UNITS)) for _ in range(4)]\n",
        "\n",
        "sample_output = encoder(example_input_batch, init_state)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBwfe07qMOUA"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-RvXiF1MOUA"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, decoder_units, batch_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm_1 = tf.keras.layers.LSTM(decoder_units,\n",
        "                                           return_sequences=True,\n",
        "                                           return_state=False)\n",
        "        self.lstm_2 = tf.keras.layers.LSTM(decoder_units,\n",
        "                                           return_sequences=True,\n",
        "                                           return_state=False)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.opt = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, x, encoder_output):\n",
        "        # x shape: (batch_size, 1, embedding_dim)\n",
        "        output = self.embedding(x)\n",
        "\n",
        "        # output shape: (batch_size, 1, decoder_units)\n",
        "        # this shape is only important for expanding decoder depth\n",
        "        output = self.lstm_1(output)\n",
        "        # flatten to feed into opt\n",
        "        # output shape: (batch_size, hidden_size)\n",
        "\n",
        "        output = self.lstm_2(output)\n",
        "        output = self.flatten(output)\n",
        "\n",
        "        # get logits\n",
        "        # x shape: (batch_size, vocab)\n",
        "        x = self.opt(output)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D1LdlK-MOUA"
      },
      "source": [
        "decoder = Decoder(target_vocab_size, EMBEDDING_DIM, DECODER_UNITS, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_input = tf.expand_dims([target_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "sample_decoder_output = decoder(sample_decoder_input, sample_output)"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0P04Qa_MOUA"
      },
      "source": [
        "### Optimizer and Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unPfCctsMOUA"
      },
      "source": [
        "Here we define the optimizer and the loss function. In our loss function we mask the zeros since that's the padding.\n",
        "\n",
        "Also of note is in the loss function. The reduction argument at default does some really wonky things which threw off all results. Had to change the reduciton to none, which at default is auto. Not exactly sure what it does in this context but it tries to sum over batches. I didn't work with it because I wanted to control all loss calculation manually. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kis6sBiBMOUA"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "static_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnIepemQMOUA"
      },
      "source": [
        "def loss_function(real, preds):\n",
        "    \"\"\"Calculate and return loss\"\"\"\n",
        "\n",
        "    # caclulate loss\n",
        "    loss = static_loss(real, preds)\n",
        "    \n",
        "    # create padding mask \n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    \n",
        "    # apply mask\n",
        "    loss *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lzJ5Y0gMOUB"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV21GU90MOUB"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inpt, trgt, init_state):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output = encoder(inpt, init_state)\n",
        "\n",
        "        # Get start token for every sequence in batch\n",
        "        dec_input = tf.expand_dims([target_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "        for i in range(1, trgt.shape[1]):\n",
        "            # dec_hidden shape: (batch_size, decoder_units)\n",
        "            # dec_input shape: (batch_size, 1)\n",
        "            predictions = decoder(dec_input, \n",
        "                                  enc_output)\n",
        "\n",
        "            loss += loss_function(trgt[:, i], predictions)\n",
        "            dec_input = tf.expand_dims(trgt[:, i], 1)\n",
        "\n",
        "    # Apply gradients \n",
        "    trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "\n",
        "    # return batch loss\n",
        "    return loss"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXRvBFyOMOUB",
        "outputId": "cbeede44-e35a-4b15-d903-d689483e6c99"
      },
      "source": [
        "EPOCHS = 20\n",
        "# encoder = Encoder(input_vocab_size, EMBEDDING_DIM, ENCODER_UNITS, \n",
        "#                   BATCH_SIZE, enc_E_mat)\n",
        "# decoder = Decoder(target_vocab_size, EMBEDDING_DIM, ATTENTION_UNITS, \n",
        "#                   DECODER_UNITS, BATCH_SIZE)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = datetime.now()\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "#     This resets the hidden state of the LSTM for every epoch\n",
        "#     init_state = [tf.zeros((BATCH_SIZE, ENCODER_UNITS)) for _ in range(4)]\n",
        "    init_state = None\n",
        "\n",
        "    for inpt, trgt in train.take(steps_per_epoch):\n",
        "        total_loss += train_step(inpt, trgt, init_state)\n",
        "\n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                        total_loss / BATCH_SIZE))\n",
        "    print('Time taken {}\\n'.format(datetime.now() - start))"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['encoder_4/embedding_9/embeddings:0', 'encoder_4/bidirectional_8/forward_lstm_18/lstm_cell_35/kernel:0', 'encoder_4/bidirectional_8/forward_lstm_18/lstm_cell_35/recurrent_kernel:0', 'encoder_4/bidirectional_8/forward_lstm_18/lstm_cell_35/bias:0', 'encoder_4/bidirectional_8/backward_lstm_18/lstm_cell_36/kernel:0', 'encoder_4/bidirectional_8/backward_lstm_18/lstm_cell_36/recurrent_kernel:0', 'encoder_4/bidirectional_8/backward_lstm_18/lstm_cell_36/bias:0', 'encoder_4/bidirectional_9/forward_lstm_19/lstm_cell_38/kernel:0', 'encoder_4/bidirectional_9/forward_lstm_19/lstm_cell_38/recurrent_kernel:0', 'encoder_4/bidirectional_9/forward_lstm_19/lstm_cell_38/bias:0', 'encoder_4/bidirectional_9/backward_lstm_19/lstm_cell_39/kernel:0', 'encoder_4/bidirectional_9/backward_lstm_19/lstm_cell_39/recurrent_kernel:0', 'encoder_4/bidirectional_9/backward_lstm_19/lstm_cell_39/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['encoder_4/embedding_9/embeddings:0', 'encoder_4/bidirectional_8/forward_lstm_18/lstm_cell_35/kernel:0', 'encoder_4/bidirectional_8/forward_lstm_18/lstm_cell_35/recurrent_kernel:0', 'encoder_4/bidirectional_8/forward_lstm_18/lstm_cell_35/bias:0', 'encoder_4/bidirectional_8/backward_lstm_18/lstm_cell_36/kernel:0', 'encoder_4/bidirectional_8/backward_lstm_18/lstm_cell_36/recurrent_kernel:0', 'encoder_4/bidirectional_8/backward_lstm_18/lstm_cell_36/bias:0', 'encoder_4/bidirectional_9/forward_lstm_19/lstm_cell_38/kernel:0', 'encoder_4/bidirectional_9/forward_lstm_19/lstm_cell_38/recurrent_kernel:0', 'encoder_4/bidirectional_9/forward_lstm_19/lstm_cell_38/bias:0', 'encoder_4/bidirectional_9/backward_lstm_19/lstm_cell_39/kernel:0', 'encoder_4/bidirectional_9/backward_lstm_19/lstm_cell_39/recurrent_kernel:0', 'encoder_4/bidirectional_9/backward_lstm_19/lstm_cell_39/bias:0'] when minimizing the loss.\n",
            "Epoch 1 Loss 118.2043\n",
            "Time taken 0:01:58.798355\n",
            "\n",
            "Epoch 2 Loss 102.9621\n",
            "Time taken 0:00:38.876684\n",
            "\n",
            "Epoch 3 Loss 96.2491\n",
            "Time taken 0:00:39.004727\n",
            "\n",
            "Epoch 4 Loss 92.0841\n",
            "Time taken 0:00:39.003300\n",
            "\n",
            "Epoch 5 Loss 89.1074\n",
            "Time taken 0:00:38.983993\n",
            "\n",
            "Epoch 6 Loss 86.6985\n",
            "Time taken 0:00:39.033888\n",
            "\n",
            "Epoch 7 Loss 84.6881\n",
            "Time taken 0:00:39.067447\n",
            "\n",
            "Epoch 8 Loss 83.0205\n",
            "Time taken 0:00:39.114792\n",
            "\n",
            "Epoch 9 Loss 81.5041\n",
            "Time taken 0:00:39.130544\n",
            "\n",
            "Epoch 10 Loss 80.2495\n",
            "Time taken 0:00:39.056233\n",
            "\n",
            "Epoch 11 Loss 79.0821\n",
            "Time taken 0:00:39.019724\n",
            "\n",
            "Epoch 12 Loss 78.0836\n",
            "Time taken 0:00:38.963129\n",
            "\n",
            "Epoch 13 Loss 77.2166\n",
            "Time taken 0:00:38.910364\n",
            "\n",
            "Epoch 14 Loss 76.4435\n",
            "Time taken 0:00:38.951223\n",
            "\n",
            "Epoch 15 Loss 75.7820\n",
            "Time taken 0:00:39.035326\n",
            "\n",
            "Epoch 16 Loss 75.1494\n",
            "Time taken 0:00:39.012864\n",
            "\n",
            "Epoch 17 Loss 74.6106\n",
            "Time taken 0:00:38.970462\n",
            "\n",
            "Epoch 18 Loss 74.1337\n",
            "Time taken 0:00:38.936559\n",
            "\n",
            "Epoch 19 Loss 73.7373\n",
            "Time taken 0:00:39.068407\n",
            "\n",
            "Epoch 20 Loss 73.3458\n",
            "Time taken 0:00:38.891191\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEr2AFkJMOUB"
      },
      "source": [
        "def evaluate(data):\n",
        "    loss = 0\n",
        "    results = []\n",
        "    bleu = 0\n",
        "\n",
        "    for i, (x, y) in enumerate(data):\n",
        "\n",
        "        result = '<start> '\n",
        "        next_word = True\n",
        "\n",
        "        # This feeds in the start token for the first initial state\n",
        "        dec_input = tf.expand_dims([target_tokenizer.word_index['<start>']], 0)\n",
        "        \n",
        "        # Get inputs\n",
        "        enc_output = encoder(x, None)\n",
        "\n",
        "        j = 1  # iterative count\n",
        "        while next_word: \n",
        "            # dec_hidden shape: (batch_size, decoder_units)\n",
        "            # dec_input shape: (batch_size, 1)\n",
        "            predictions = decoder(dec_input, enc_output)\n",
        "            loss += loss_function(y[:, j], predictions)\n",
        "            \n",
        "            # max logit for tokenized word\n",
        "            word_idx = tf.argmax(predictions[0]).numpy()\n",
        "            word = target_tokenizer.index_word[word_idx]\n",
        "            result += word + ' '\n",
        "\n",
        "            dec_input = tf.expand_dims([word_idx], 0)\n",
        "\n",
        "            if word == '<end>':\n",
        "                next_word = False\n",
        "            \n",
        "            if j >= y.shape[1] - 1:\n",
        "                result += '<end>'\n",
        "                next_word = False\n",
        "            \n",
        "            j += 1\n",
        "\n",
        "        results.append(result)\n",
        "        bleu += sentence_bleu(f_holdout[i], result)\n",
        "\n",
        "    return results, loss.numpy() / len(f_holdout), bleu / len(f_holdout)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vft0SHsNEBNk"
      },
      "source": [
        "results, test_loss, bleu = evaluate(test)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyrwQzJ2aJXJ",
        "outputId": "fec820e8-4b56-40a5-e4c0-4f5966c78101"
      },
      "source": [
        "test_loss"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39.462165350539294"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7UPBTU-aZiY",
        "outputId": "b942c87d-8889-4390-8ea1-b6b19d1c0bd1"
      },
      "source": [
        "bleu"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8322362969156308"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wTckbSho89o",
        "outputId": "242a6df1-fa9d-4cb8-91ea-eb7fe2b1b429",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "corpus_bleu(f_holdout, results)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8326549060715791"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RXdV1DNZqAj"
      },
      "source": [
        "def examine(index):\n",
        "    print(\"Informal: \", if_holdout[index])\n",
        "    print(\"Formal: \", f_holdout[index])\n",
        "    print(\"Predicted: \", results[index])\n",
        "    print(\"Sequence BLEU: \", sentence_bleu(f_holdout[index], results[index]))"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNS9wCEOaOmH",
        "outputId": "14a02174-81c0-4473-9ec3-c278e96bbf07"
      },
      "source": [
        "examine(1000)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Informal:  <start> Ask him to spell his name . . . m o r o . . .  <end>\n",
            "Formal:  <start> If you ask him to spell his name he would say , M o r o . . .  <end>\n",
            "Predicted:  <start> i am not know <end> \n",
            "Sequence BLEU:  0.855526185871245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaGj0Ihir2Kp"
      },
      "source": [
        "with open(BASE_PATH + '/Results/vanilla_encoder_decoder_results_custom', 'w') as f:\n",
        "    for seq in results:\n",
        "        f.write(seq + '\\n')"
      ],
      "execution_count": 153,
      "outputs": []
    }
  ]
}