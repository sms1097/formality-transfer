{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention is All You Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "import re \n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare Static Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parameters are mostly stolen from the Google Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 256\n",
    "ATTENTION_UNITS = 10\n",
    "ENCODER_UNITS = 1024\n",
    "DECODER_UNITS = 1024\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "formal = open('../Data/Supervised Data/Entertainment_Music/S_Formal_EM_Train.txt').read()\n",
    "informal = open('../Data/Supervised Data/Entertainment_Music/S_Informal_EM_Train.txt').read()\n",
    "\n",
    "formal_holdout = open('../Data/Supervised Data/Entertainment_Music/S_Formal_EM_ValTest.txt').read()\n",
    "informal_holdout = open('../Data/Supervised Data/Entertainment_Music/S_Informal_EM_ValTest.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sequence(seq):\n",
    "    \"\"\"This inserts a space in between the last word and a period\"\"\"\n",
    "    s = re.sub('([.,!?()])', r' \\1 ', seq)\n",
    "    s = re.sub('\\s{2,}', ' ', s)\n",
    "    \n",
    "    return '<start> ' + s + ' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_corpus = [process_sequence(seq) for seq in formal.split('\\n')]\n",
    "if_corpus = [process_sequence(seq) for seq in informal.split('\\n')]\n",
    "\n",
    "f_holdout = [process_sequence(seq) for seq in formal_holdout.split('\\n')]\n",
    "if_holdout = [process_sequence(seq) for seq in informal_holdout.split('\\n')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    \"\"\" Tokenize data and pad sequences \"\"\"\n",
    "    tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', oov_token='<OOV>')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    \n",
    "    seqs = tokenizer.texts_to_sequences(corpus)\n",
    "    padded_seqs = pad_sequences(seqs, padding='post')\n",
    "    return padded_seqs, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, input_tokenizer = tokenize(if_corpus)\n",
    "target_train, target_tokenizer = tokenize(f_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = len(input_train)\n",
    "steps_per_epoch = len(input_train) // BATCH_SIZE\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
    "\n",
    "train = tf.data.Dataset.from_tensor_slices((input_train, target_train)).shuffle(buffer_size)\n",
    "train = train.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input_batch, example_target_batch = next(iter(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_embedding(p, model_size):\n",
    "    p_emb = np.zeros((1, model_size))\n",
    "    for i in range(model_size):\n",
    "        if i % 2 == 0:\n",
    "            p_emb[:, i] = np.sin(p / 10000 ** (i / model_size))\n",
    "        else:\n",
    "            p_emb[:, i] = np.cos(p / 10000 ** (i / model_size))\n",
    "    return p_emb\n",
    "\n",
    "max_length = input_train.shape[1]\n",
    "MODEL_SIZE = 128\n",
    "\n",
    "pes = [positional_embedding(i, MODEL_SIZE) for i in range(max_length)]\n",
    "\n",
    "pes = np.concatenate(pes, axis=0)\n",
    "pes = tf.constant(pes, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing \n",
    "$$ \\text{MultiHead}(Q, K, V) = \\text{Concat}(head_1,...,head_h)W^o$$ \n",
    "where $$head_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)$$\n",
    "and attention is \n",
    "$$ \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, model_size, h):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.query_size = model_size // h\n",
    "        self.key_size = model_size // h\n",
    "        self. value_size = model_size // h\n",
    "        self.h = h\n",
    "        self.wq = [tf.keras.layers.Dense(self.query_size) for _ in range(h)]\n",
    "        self.wk = [tf.keras.layers.Dense(self.key_size) for _ in range(h)]\n",
    "        self.wv = [tf.keras.layers.Dense(self.value_size) for _ in range(h)]\n",
    "        self.wo = tf.keras.layers.Dense(model_size)\n",
    "\n",
    "    def __one_head_attention(self, query, value, i):\n",
    "        \"\"\"run for each query, value, key in h\"\"\"\n",
    "        # query shape: (batch_size, query_length, model_size)\n",
    "        # value shape: (batch_size, value_length, model_size)\n",
    "        score = tf.matmul(self.wq[i](query), self.wk[i](value), transpose_b=True)\n",
    "\n",
    "        # eq(1) from AAYN\n",
    "        d_k = tf.math.sqrt(tf.cast(self.key_size, dtype=tf.float32))\n",
    "\n",
    "        # score shape: (batch_size, query_length, value_length)\n",
    "        score /= d_k\n",
    "\n",
    "        # attention shape: (batch_size, query_length, value_length)\n",
    "        attention = tf.nn.softmax(score, axis=2)\n",
    "\n",
    "        # context shape: (batch_size, query_length, value_length)\n",
    "        head = tf.matmul(attention, value)\n",
    "\n",
    "        return head \n",
    "\n",
    "    def call(self, query, value):\n",
    "        \"\"\"This computes the multi head attention by calling for each h\"\"\"\n",
    "        # compute one head attention for each head\n",
    "        multi_head = [self.__one_head_attention(query, value, i) for i in range(self.h)]\n",
    "\n",
    "        # concat all heads \n",
    "        multi_head = tf.concat(multi_head, axis=2)\n",
    "\n",
    "        # multi_head shape: (batch_size, query_length, model_size)\n",
    "        mutli_head = self.wo(multi_head)\n",
    "\n",
    "        return mutli_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, model_size, num_layers, h):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.model_size = model_size\n",
    "        self.num_layers = num_layers\n",
    "        self.h = h\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, model_size)\n",
    "\n",
    "        self.attention = [MultiHeadAttention(model_size, h) for _ in range(num_layers)]\n",
    "        self.attention_norm = [tf.keras.layers.BatchNormalization() for _ in range(num_layers)]\n",
    "\n",
    "        self.FFN_l1 = [tf.keras.layers.Dense(4 * model_size, activation='relu') for _ in range(num_layers)]\n",
    "        self.FFN_l2 = [tf.keras.layers.Dense(model_size) for _ in range(num_layers)]\n",
    "        self.FFN_norm = [tf.keras.layers.BatchNormalization() for _ in range(num_layers)]\n",
    "\n",
    "    def call(self, seq):\n",
    "        sub_in = []\n",
    "        for i in range(seq.shape[1]):\n",
    "            E = self.embedding(tf.expand_dims(seq[:, i], axis=1))\n",
    "            sub_in.append(E + pes[i, :])\n",
    "\n",
    "        sub_in = tf.concat(sub_in, axis=1)\n",
    "\n",
    "        # MultiHeadAttention\n",
    "        for i in range(self.num_layers):\n",
    "            sub_out = [self.attention[i](\n",
    "                tf.expand_dims(sub_in[:, j, :], axis=1), sub_in)\n",
    "            for j in range(sub_in.shape[1])]\n",
    "\n",
    "            # sub_out shape: (batch_size, sequence_length, model_size)\n",
    "            sub_out = tf.concat(sub_out, axis=1)\n",
    "\n",
    "            # norm and add\n",
    "            sub_out = self.attention_norm[i](sub_out + sub_in)\n",
    "\n",
    "            # Feed Forward Network\n",
    "            FFN_out = self.FFN_l2[i](self.FFN_l1[i](sub_out))\n",
    "\n",
    "            #  add and norm\n",
    "            FFN_out = self.FFN_norm[i](FFN_out + sub_out)\n",
    "\n",
    "        return FFN_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, model_size, num_layers, h):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.model_size = model_size\n",
    "        self.num_layers = num_layers\n",
    "        self.h = h\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, model_size)\n",
    "\n",
    "        self.mha1 = [MultiHeadAttention(model_size, h) for _ in range(num_layers)]\n",
    "        self.mha1_norm = [tf.keras.layers.BatchNormalization() for _ in range(num_layers)]\n",
    "        self.mha2 = [MultiHeadAttention(model_size, h) for _ in range(num_layers)]\n",
    "        self.mha2_norm = [tf.keras.layers.BatchNormalization() for _ in range(num_layers)]\n",
    "\n",
    "        self.FFN_l1 = [tf.keras.layers.Dense(4 * model_size) for _ in range(num_layers)]\n",
    "        self.FFN_l2 = [tf.keras.layers.Dense(model_size) for _ in range(num_layers)]\n",
    "        self.FFN_norm = [tf.keras.layers.BatchNormalization() for _ in range(num_layers)]\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, seq, enc_opt):\n",
    "        E = [self.embedding(tf.expand_dims(seq[:, i], axis=1)) + pes[i,:]\n",
    "                     for i in range(seq.shape[1])]\n",
    "        E_out = tf.concat(E, axis=1)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            # First MHA layer\n",
    "            mha1_out = [self.mha1[i](\n",
    "                tf.expand_dims(E_out[:, j, :], axis=1),\n",
    "                E_out[:, :j, :]\n",
    "            ) for j in range(E_out.shape[1])]\n",
    "            \n",
    "            # add and norm\n",
    "            mha1_out = tf.concat(mha1_out, axis=1)\n",
    "            mha1_out = self.mha1_norm[i](mha1_out + E_out)\n",
    "            \n",
    "            # Second MHA layer\n",
    "            mha2_out = [self.mha2[i](\n",
    "                tf.expand_dims(mha1_out[:, j, :], axis=1), \n",
    "                enc_output\n",
    "            ) for j in range(mha1_out.shape[1])]\n",
    "            \n",
    "            # add and norm\n",
    "            mha2_out = tf.concat(mha2_out, axis=1)\n",
    "            mha2_out = self.mha2_norm[i](mha2_out + mha1_out)\n",
    "            \n",
    "            # FFN\n",
    "            FFN_out = self.FFN_l2[i](self.FFN_l1[i](mha2_out))\n",
    "            FFN_out = self.FFN_norm[i](FFN_out + mha2_out)\n",
    "        \n",
    "            output = self.fc(FFN_out)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 2\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "example_input_sequence = example_input_batch[0]\n",
    "example_output_sequence = example_target_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_vocab_size, MODEL_SIZE, NUM_LAYERS, H)\n",
    "decoder = Decoder(target_vocab_size, MODEL_SIZE, NUM_LAYERS, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sequence_in = tf.constant([[1, 2, 3, 4, 6, 7, 8, 0, 0, 0], \n",
    "                              [1, 2, 3, 4, 6, 7, 8, 0, 0, 0]])\n",
    "fr_sequence_in = tf.constant([[1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0],\n",
    "                              [1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=int32, numpy=\n",
       "array([[1, 2, 3, 4, 6, 7, 8, 0, 0, 0],\n",
       "       [1, 2, 3, 4, 6, 7, 8, 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sequence_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = tf.reshape(example_input_sequence, (1,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_output = encoder(ex)\n",
    "dec_output = decoder(fr_sequence_in, enc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
