{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention is All You Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "import re \n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare Static Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "D_MODEL = 512\n",
    "NX = 6\n",
    "H = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qzSYxc4yMOT_"
   },
   "outputs": [],
   "source": [
    "BASE_PATH = '../Data'\n",
    "\n",
    "FORMAL_PATH_TRAIN = '{}/Supervised Data/Entertainment_Music/S_Formal_EM_Train.txt'.format(BASE_PATH)\n",
    "INFORMAL_PATH_TRAIN = '{}/Supervised Data/Entertainment_Music/S_Informal_EM_Train.txt'.format(BASE_PATH)\n",
    "\n",
    "FORMAL_PATH_HOLDOUT = '{}/Supervised Data/Entertainment_Music/S_Formal_EM_ValTest.txt'.format(BASE_PATH)\n",
    "INFORMAL_PATH_HOLDOUT = '{}/Supervised Data/Entertainment_Music/S_Informal_EM_ValTest.txt'.format(BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "x6EaDkEtMOUA"
   },
   "outputs": [],
   "source": [
    "formal = open(FORMAL_PATH_TRAIN).read()\n",
    "informal = open(INFORMAL_PATH_TRAIN).read()\n",
    "\n",
    "formal_holdout = open(FORMAL_PATH_HOLDOUT).read()\n",
    "informal_holdout = open(INFORMAL_PATH_HOLDOUT).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sequence(seq):\n",
    "    \"\"\"This inserts a space in between the last word and a period\"\"\"\n",
    "    s = re.sub('([.,!?()])', r' \\1 ', seq)\n",
    "    s = re.sub('\\s{2,}', ' ', s)\n",
    "    \n",
    "    return '<start> ' + s + ' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_seq_target_input(seq):\n",
    "    \"\"\"\n",
    "    This inserts a space in between the last word and a period\n",
    "    This function covers shifting right for being fed to the Transformer\n",
    "    \"\"\"\n",
    "    \n",
    "    s = re.sub('([.,!?()])', r' \\1 ', seq)\n",
    "    s = re.sub('\\s{2,}', ' ', s)\n",
    "    \n",
    "    return s + ' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_corpus = [process_sequence(seq) for seq in formal.split('\\n')]\n",
    "f_corpus_input = [process_seq_target_input(seq) for seq in formal.split('\\n')]\n",
    "if_corpus = [process_sequence(seq) for seq in informal.split('\\n')]\n",
    "\n",
    "f_holdout = [process_sequence(seq) for seq in formal_holdout.split('\\n')]\n",
    "if_holdout = [process_sequence(seq) for seq in informal_holdout.split('\\n')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "czog7VXRMOUA"
   },
   "outputs": [],
   "source": [
    "def tokenize(corpus, tokenizer=None, maxlen=None):\n",
    "    \"\"\" Tokenize data and pad sequences \"\"\"\n",
    "    if not tokenizer: \n",
    "        tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', \n",
    "                              oov_token='<OOV>')\n",
    "        tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    seqs = tokenizer.texts_to_sequences(corpus)\n",
    "    padded_seqs = pad_sequences(seqs, padding='post', maxlen=maxlen)\n",
    "\n",
    "    return padded_seqs, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, input_tokenizer = tokenize(if_corpus)\n",
    "target_train, target_tokenizer = tokenize(f_corpus)\n",
    "target_input_train, target_input_tokenizer = tokenize(f_corpus_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = len(input_train)\n",
    "steps_per_epoch = len(input_train) // BATCH_SIZE\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
    "\n",
    "train = tf.data.Dataset.from_tensor_slices((input_train, target_input_train, target_train)).shuffle(buffer_size)\n",
    "train = train.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input_batch, example_target_input_batch, example_target_batch = next(iter(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to compute Positional Embeddign from 3.5\n",
    "\n",
    "$$ PE_{(pos, 2i)} = \\sin(pos, 10000^{2i/d_{model}}) \\\\\n",
    "PE_{(pos, 2i+1)} = \\cos(pos, 10000^{2i/d_{model}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 42)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_input_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_embedding(p, d_model):\n",
    "    p_emb = np.zeros((1, d_model))\n",
    "    for i in range(d_model):\n",
    "        if i % 2 == 0:\n",
    "            p_emb[:, i] = np.sin(p / 10000 ** (i / d_model))\n",
    "        else:\n",
    "            p_emb[:, i] = np.cos(p / 10000 ** (i / d_model))\n",
    "    return p_emb\n",
    "\n",
    "MAX_LENGTH = max(input_train.shape[1], target_input_train.shape[1], target_train.shape[1])\n",
    "\n",
    "pes = [positional_embedding(i, D_MODEL) for i in range(MAX_LENGTH)]\n",
    "\n",
    "pes = np.concatenate(pes, axis=0)\n",
    "pes = tf.constant(pes, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing \n",
    "$$ \\text{MultiHead}(Q, K, V) = \\text{Concat}(head_1,...,head_h)W^o$$ \n",
    "where $$head_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)$$\n",
    "and attention is \n",
    "$$ \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In seciton 3.2.3 of AAYN encoder-decoder for seq2seq models keys and values are both form the encoder output, so treating key and value as the same input here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.Model):\n",
    "    def __init__(self, model_size, h):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.mha_size = model_size // h\n",
    "        self.h = h\n",
    "\n",
    "        # learn different weights for all \n",
    "        self.wq = [tf.keras.layers.Dense(self.mha_size) for _ in range(h)]\n",
    "        self.wk = [tf.keras.layers.Dense(self.mha_size) for _ in range(h)]\n",
    "        self.wv = [tf.keras.layers.Dense(self.mha_size) for _ in range(h)]\n",
    "        self.wo = tf.keras.layers.Dense(model_size)\n",
    "\n",
    "    def scaled_dot_product_attention(self, q, k, i, mask=None):\n",
    "        \"\"\"run for each query, value, key in h\"\"\"\n",
    "        # query shape: (batch_size, query_length, model_size)\n",
    "        # value shape: (batch_size, key_length, model_size)\n",
    "        score = tf.matmul(self.wq[i](q), self.wk[i](k), transpose_b=True)\n",
    "\n",
    "        # eq(1) from AAYN\n",
    "        d_k = tf.math.sqrt(tf.cast(self.mha_size, dtype=tf.float32))\n",
    "\n",
    "        # score shape: (batch_size, query_length, value_length)\n",
    "        score /= d_k\n",
    "\n",
    "        # apply mask\n",
    "        if mask:\n",
    "            score += mask * 1e-8\n",
    "\n",
    "        # attention shape: (batch_size, query_length, value_length)\n",
    "        attention = tf.nn.softmax(score, axis=2)\n",
    "\n",
    "        # context shape: (batch_size, query_length, value_length)\n",
    "        head = tf.matmul(attention, self.wv[i](k))\n",
    "\n",
    "        return head \n",
    "\n",
    "    def call(self, q, k, mask=None):\n",
    "        \"\"\"This computes the multi head attention by calling for each h\"\"\"\n",
    "        # compute one head attention for each head\n",
    "        multi_head = [self.scaled_dot_product_attention(q, k, i, mask) for i in range(self.h)]\n",
    "        \n",
    "        # concat all heads \n",
    "        multi_head = tf.concat(multi_head, axis=2)\n",
    "\n",
    "        # multi_head shape: (batch_size, query_length, model_size)\n",
    "        mutli_head = self.wo(multi_head)\n",
    "\n",
    "        return mutli_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, d_model, h):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.h = h \n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, h)\n",
    "        self.mha_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "        self.FFN_l1 = tf.keras.layers.Dense(4 * d_model, activation='relu')\n",
    "        self.FFN_l2 = tf.keras.layers.Dense(d_model)\n",
    "        self.FFN_norm = tf.keras.layers.LayerNormalization()\n",
    "    \n",
    "    def call(self, E_out, mask=None):\n",
    "        # MultiHead Attention\n",
    "        mha_out = self.mha(E_out, E_out, mask)\n",
    "        mha_out = self.mha_norm(E_out + mha_out)\n",
    "\n",
    "        # Feed Forward Network\n",
    "        FFN_out = self.FFN_l2(self.FFN_l1(mha_out))\n",
    "\n",
    "        #  add and norm\n",
    "        FFN_out = self.FFN_norm(FFN_out + mha_out)\n",
    "        \n",
    "        return FFN_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, h):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.h = h\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model)\n",
    "        self.encoder_layers = [EncoderLayer(vocab_size, d_model, h) \n",
    "                               for _ in range(num_layers)]\n",
    "        \n",
    "    def call(self, seq, mask=None):\n",
    "        \n",
    "        # Embedding Layer\n",
    "        # E_out shape: (batch_size x max_length x d_model)\n",
    "        E_out = self.embedding(seq)\n",
    "        \n",
    "        # create x variable\n",
    "        x = E_out\n",
    "\n",
    "        # MultiHeadAttention\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.encoder_layers[i](x, mask)\n",
    "            \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_vocab_size, D_MODEL, NX, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.Model):\n",
    "    def __init__(self, d_model, h):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.mha1 = MultiHeadAttention(d_model, h)\n",
    "        self.mha1_norm = tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "        self.mha2 = MultiHeadAttention(d_model, h)\n",
    "        self.mha2_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "        self.FFN_l1 = tf.keras.layers.Dense(4 * d_model)\n",
    "        self.FFN_l2 = tf.keras.layers.Dense(d_model)\n",
    "        self.FFN_norm = tf.keras.layers.LayerNormalization()\n",
    "    \n",
    "    def call(self, x, enc_opt, mask=None):\n",
    "        # create padding mask\n",
    "        pad_mask = tf.linalg.band_part(tf.ones((len(x), len(x))), -1, 0)\n",
    "\n",
    "        # First MHA layer\n",
    "        # mha1_out shape: \n",
    "        mha1_out = self.mha1(x, x, pad_mask)\n",
    "        mha1_out = self.mha1_norm(mha1_out + x)\n",
    "\n",
    "        # Second MHA layer\n",
    "        # mha2_out shape: \n",
    "        mha2_out = self.mha2(x, enc_opt, pad_mask)\n",
    "        mha2_out = self.mha2_norm(mha2_out + mha1_out)\n",
    "\n",
    "        # FFN\n",
    "        # FFN_out shape: \n",
    "        FFN_out = self.FFN_l2(self.FFN_l1(mha2_out))\n",
    "        FFN_out = self.FFN_norm(FFN_out + mha2_out)\n",
    "        \n",
    "        return FFN_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, h):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model)\n",
    "        self.decoder_layers = [DecoderLayer(d_model, h)\n",
    "                              for _ in range(num_layers)]\n",
    "        self.opt = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, seq, enc_opt, mask=None):\n",
    "        x = self.embedding(seq)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.decoder_layers[i](x, enc_opt)\n",
    "        \n",
    "        output = self.opt(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input_sequence = example_input_batch[0]\n",
    "example_output_sequence = example_target_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_vocab_size, D_MODEL, NX, H)\n",
    "decoder = Decoder(target_vocab_size, D_MODEL, NX, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = tf.reshape(example_input_sequence, (1,example_input_sequence.shape[0]))\n",
    "ex1 = tf.reshape(example_output_sequence, (1,example_output_sequence.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_output = encoder(ex)\n",
    "dec_output = decoder(ex1, enc_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "static_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True)\n",
    "\n",
    "def loss_func(real, preds):\n",
    "    \"\"\"Calculate and return loss\"\"\"\n",
    "    # caclulate loss\n",
    "    loss = static_loss(real, preds)\n",
    "\n",
    "    # create mask \n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "\n",
    "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(in_seq, targ_in_seq, targ_out_seq):\n",
    "    with tf.GradientTape() as tape:\n",
    "        mask = 1 - tf.cast(tf.equal(in_seq, 0), dtype=tf.float32)\n",
    "        enc_opt = encoder(in_seq, mask)\n",
    "        dec_opt = decoder(targ_in_seq, enc_opt, mask)\n",
    "        loss = loss_func(targ_out_seq, dec_opt)\n",
    "        \n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return loss / targ_out_seq.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "start = datetime.now()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss=0\n",
    "    for batch, (inpt, targ_inpt, targ_out) in enumerate(train.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inpt, targ_inpt, targ_out)\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "    if batch % 100 == 0:\n",
    "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch+1,\n",
    "                                                     batch,\n",
    "                                                     batch_loss.numpy()))\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch+1,\n",
    "                                        total_loss/steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} seconds\\n'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
