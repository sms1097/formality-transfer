{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder MT Attention Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "formal = open('../Data/Supervised Data/Entertainment_Music/S_Formal_EM_Train.txt').read()\n",
    "informal = open('../Data/Supervised Data/Entertainment_Music/S_Informal_EM_Train.txt').read()\n",
    "\n",
    "formal_holdout = open('../Data/Supervised Data/Entertainment_Music/S_Formal_EM_ValTest.txt').read()\n",
    "informal_holdout = open('../Data/Supervised Data/Entertainment_Music/S_Informal_EM_ValTest.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_corpus = ['<start> ' + seq + ' <end>' for seq in formal.split('\\n')]\n",
    "if_corpus = ['<start> ' + seq + ' <end>' for seq in informal.split('\\n')]\n",
    "\n",
    "f_holdout = ['<start> ' + seq + ' <end>' for seq in formal_holdout.split('\\n')]\n",
    "if_holdout = ['<start> ' + seq + ' <end>' for seq in informal_holdout.split('\\n')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    \"\"\" Tokenize data and return tokenizer \"\"\"\n",
    "    tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', oov_token='<OOV>')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    \n",
    "    seqs = tokenizer.texts_to_sequences(corpus)\n",
    "    padded_seqs = pad_sequences(seqs, padding='post')\n",
    "    return padded_seqs, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, input_tokenizer = tokenize(if_corpus)\n",
    "target_train, target_tokenizer = tokenize(f_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " '<start>': 2,\n",
       " '<end>': 3,\n",
       " 'i': 4,\n",
       " 'the': 5,\n",
       " 'and': 6,\n",
       " 'a': 7,\n",
       " 'it': 8,\n",
       " 'to': 9,\n",
       " 'you': 10,\n",
       " 'is': 11,\n",
       " 'that': 12,\n",
       " 'of': 13,\n",
       " 'but': 14,\n",
       " 'in': 15,\n",
       " 'like': 16,\n",
       " 'on': 17,\n",
       " 'have': 18,\n",
       " 'they': 19,\n",
       " 'my': 20,\n",
       " 'for': 21,\n",
       " 'not': 22,\n",
       " 'he': 23,\n",
       " 'if': 24,\n",
       " 'was': 25,\n",
       " 'just': 26,\n",
       " 'think': 27,\n",
       " 'know': 28,\n",
       " 'me': 29,\n",
       " \"don't\": 30,\n",
       " 'so': 31,\n",
       " 'are': 32,\n",
       " 'with': 33,\n",
       " 'be': 34,\n",
       " 'no': 35,\n",
       " 'good': 36,\n",
       " 'or': 37,\n",
       " 'one': 38,\n",
       " 'all': 39,\n",
       " 'u': 40,\n",
       " 'she': 41,\n",
       " 'do': 42,\n",
       " 'what': 43,\n",
       " 'get': 44,\n",
       " 'go': 45,\n",
       " 'can': 46,\n",
       " 'its': 47,\n",
       " 'out': 48,\n",
       " 'love': 49,\n",
       " 'your': 50,\n",
       " 'this': 51,\n",
       " 'there': 52,\n",
       " 'song': 53,\n",
       " 'her': 54,\n",
       " 'dont': 55,\n",
       " 'would': 56,\n",
       " 'movie': 57,\n",
       " 'up': 58,\n",
       " 'about': 59,\n",
       " 'at': 60,\n",
       " \"it's\": 61,\n",
       " 'really': 62,\n",
       " 'them': 63,\n",
       " 'com': 64,\n",
       " 'his': 65,\n",
       " 'because': 66,\n",
       " 'from': 67,\n",
       " 'music': 68,\n",
       " 'too': 69,\n",
       " 'got': 70,\n",
       " 'then': 71,\n",
       " 'by': 72,\n",
       " 'who': 73,\n",
       " 'him': 74,\n",
       " 'will': 75,\n",
       " 'some': 76,\n",
       " 'has': 77,\n",
       " \"i'm\": 78,\n",
       " 'as': 79,\n",
       " 'say': 80,\n",
       " 'now': 81,\n",
       " '2': 82,\n",
       " 'want': 83,\n",
       " 'more': 84,\n",
       " 'well': 85,\n",
       " 'yes': 86,\n",
       " 'when': 87,\n",
       " 'big': 88,\n",
       " 'try': 89,\n",
       " 'how': 90,\n",
       " 'best': 91,\n",
       " 'see': 92,\n",
       " 'did': 93,\n",
       " 'great': 94,\n",
       " 'show': 95,\n",
       " 'an': 96,\n",
       " 'find': 97,\n",
       " 'even': 98,\n",
       " 'im': 99,\n",
       " 'sure': 100,\n",
       " 'people': 101,\n",
       " \"can't\": 102,\n",
       " 'way': 103,\n",
       " 'never': 104,\n",
       " 'time': 105,\n",
       " 'why': 106,\n",
       " 'look': 107,\n",
       " 'name': 108,\n",
       " 'yahoo': 109,\n",
       " 'guy': 110,\n",
       " 'only': 111,\n",
       " 'right': 112,\n",
       " 'lol': 113,\n",
       " 'much': 114,\n",
       " 'songs': 115,\n",
       " 'oh': 116,\n",
       " 'am': 117,\n",
       " 'girl': 118,\n",
       " 'yeah': 119,\n",
       " 'man': 120,\n",
       " 'day': 121,\n",
       " 'pretty': 122,\n",
       " 'watch': 123,\n",
       " '1': 124,\n",
       " 'any': 125,\n",
       " 'could': 126,\n",
       " 'back': 127,\n",
       " 'ever': 128,\n",
       " 'answer': 129,\n",
       " 'though': 130,\n",
       " 'make': 131,\n",
       " 'question': 132,\n",
       " 'heard': 133,\n",
       " 'better': 134,\n",
       " 'luck': 135,\n",
       " 'should': 136,\n",
       " 'their': 137,\n",
       " 'still': 138,\n",
       " 'we': 139,\n",
       " 'funny': 140,\n",
       " 'other': 141,\n",
       " 'had': 142,\n",
       " 'here': 143,\n",
       " 'side': 144,\n",
       " 'bad': 145,\n",
       " 'www': 146,\n",
       " 'maybe': 147,\n",
       " 'first': 148,\n",
       " 'old': 149,\n",
       " 'very': 150,\n",
       " 'mean': 151,\n",
       " 'thats': 152,\n",
       " 'r': 153,\n",
       " 'where': 154,\n",
       " 'going': 155,\n",
       " 'also': 156,\n",
       " \"he's\": 157,\n",
       " 'said': 158,\n",
       " '3': 159,\n",
       " 'hot': 160,\n",
       " 'little': 161,\n",
       " 'movies': 162,\n",
       " 'tell': 163,\n",
       " 'left': 164,\n",
       " 'below': 165,\n",
       " 'sorry': 166,\n",
       " 'something': 167,\n",
       " 'were': 168,\n",
       " 'hope': 169,\n",
       " 'does': 170,\n",
       " 'ask': 171,\n",
       " 'new': 172,\n",
       " \"didn't\": 173,\n",
       " 'rock': 174,\n",
       " 'off': 175,\n",
       " 'both': 176,\n",
       " 'guess': 177,\n",
       " 'down': 178,\n",
       " 'seen': 179,\n",
       " 'lot': 180,\n",
       " 'squares': 181,\n",
       " 'play': 182,\n",
       " 'thing': 183,\n",
       " 'cool': 184,\n",
       " 'stuff': 185,\n",
       " 'always': 186,\n",
       " 'than': 187,\n",
       " 'probably': 188,\n",
       " 'check': 189,\n",
       " 'search': 190,\n",
       " 'need': 191,\n",
       " 'ur': 192,\n",
       " 'life': 193,\n",
       " \"that's\": 194,\n",
       " 'anything': 195,\n",
       " 'ok': 196,\n",
       " 'fun': 197,\n",
       " '4': 198,\n",
       " 'band': 199,\n",
       " 'download': 200,\n",
       " 'real': 201,\n",
       " 'called': 202,\n",
       " 'free': 203,\n",
       " 'tv': 204,\n",
       " 'been': 205,\n",
       " 'limewire': 206,\n",
       " 'many': 207,\n",
       " 'come': 208,\n",
       " 'thought': 209,\n",
       " 'cant': 210,\n",
       " 'stupid': 211,\n",
       " 'looks': 212,\n",
       " 'give': 213,\n",
       " 'listen': 214,\n",
       " 'looking': 215,\n",
       " 'ya': 216,\n",
       " 'over': 217,\n",
       " 'hey': 218,\n",
       " 'remember': 219,\n",
       " 'b': 220,\n",
       " 'use': 221,\n",
       " 'same': 222,\n",
       " 'saw': 223,\n",
       " \"i've\": 224,\n",
       " 'cd': 225,\n",
       " 'again': 226,\n",
       " 'baby': 227,\n",
       " 'type': 228,\n",
       " 'most': 229,\n",
       " 'let': 230,\n",
       " 'cause': 231,\n",
       " 'last': 232,\n",
       " 'made': 233,\n",
       " 'favorite': 234,\n",
       " '5': 235,\n",
       " 'take': 236,\n",
       " 'boy': 237,\n",
       " 'wanna': 238,\n",
       " 'google': 239,\n",
       " 'website': 240,\n",
       " 'hate': 241,\n",
       " 'sing': 242,\n",
       " 'says': 243,\n",
       " 'two': 244,\n",
       " 'help': 245,\n",
       " 'read': 246,\n",
       " 'lyrics': 247,\n",
       " '10': 248,\n",
       " 'gay': 249,\n",
       " \"you're\": 250,\n",
       " 'd': 251,\n",
       " 'gonna': 252,\n",
       " 'green': 253,\n",
       " 'put': 254,\n",
       " 'friend': 255,\n",
       " 'buy': 256,\n",
       " 'after': 257,\n",
       " 'might': 258,\n",
       " 'used': 259,\n",
       " \"she's\": 260,\n",
       " 'girls': 261,\n",
       " 'actually': 262,\n",
       " 'believe': 263,\n",
       " 'someone': 264,\n",
       " 'e': 265,\n",
       " 'hell': 266,\n",
       " 'awesome': 267,\n",
       " 'points': 268,\n",
       " 'before': 269,\n",
       " 'questions': 270,\n",
       " 'hard': 271,\n",
       " 'those': 272,\n",
       " 'wait': 273,\n",
       " 'cuz': 274,\n",
       " 'guys': 275,\n",
       " 'rap': 276,\n",
       " 'n': 277,\n",
       " \"i'd\": 278,\n",
       " 'work': 279,\n",
       " 'sounds': 280,\n",
       " 'else': 281,\n",
       " 'kind': 282,\n",
       " 'idea': 283,\n",
       " 'own': 284,\n",
       " 'o': 285,\n",
       " 'every': 286,\n",
       " 'kinda': 287,\n",
       " 'wrong': 288,\n",
       " 'anyone': 289,\n",
       " 'hear': 290,\n",
       " 'black': 291,\n",
       " 'long': 292,\n",
       " 't': 293,\n",
       " 's': 294,\n",
       " 'alot': 295,\n",
       " 'year': 296,\n",
       " 'nothing': 297,\n",
       " 'video': 298,\n",
       " 'site': 299,\n",
       " \"doesn't\": 300,\n",
       " 'c': 301,\n",
       " 'kids': 302,\n",
       " \"they're\": 303,\n",
       " 'friends': 304,\n",
       " 'yo': 305,\n",
       " 'album': 306,\n",
       " 'around': 307,\n",
       " 'course': 308,\n",
       " 'yet': 309,\n",
       " 'money': 310,\n",
       " 'nice': 311,\n",
       " 'hes': 312,\n",
       " 'which': 313,\n",
       " 'fan': 314,\n",
       " 'another': 315,\n",
       " 'either': 316,\n",
       " 'care': 317,\n",
       " 'live': 318,\n",
       " 'head': 319,\n",
       " \"i'll\": 320,\n",
       " 'into': 321,\n",
       " 'things': 322,\n",
       " 'home': 323,\n",
       " 'pick': 324,\n",
       " 'person': 325,\n",
       " 'american': 326,\n",
       " 'ugly': 327,\n",
       " 'w': 328,\n",
       " 'liked': 329,\n",
       " 'once': 330,\n",
       " 'talking': 331,\n",
       " 'sound': 332,\n",
       " 'dance': 333,\n",
       " 'call': 334,\n",
       " 'singer': 335,\n",
       " 'cute': 336,\n",
       " 'years': 337,\n",
       " 'dude': 338,\n",
       " \"haven't\": 339,\n",
       " 'etc': 340,\n",
       " 'keep': 341,\n",
       " 'p': 342,\n",
       " 'chris': 343,\n",
       " 'god': 344,\n",
       " 'since': 345,\n",
       " 'voice': 346,\n",
       " 'depends': 347,\n",
       " 'already': 348,\n",
       " 'yea': 349,\n",
       " 'please': 350,\n",
       " 'these': 351,\n",
       " 'such': 352,\n",
       " '50': 353,\n",
       " 'crazy': 354,\n",
       " 'dead': 355,\n",
       " 'sexy': 356,\n",
       " 'gets': 357,\n",
       " 'next': 358,\n",
       " \"wouldn't\": 359,\n",
       " 'went': 360,\n",
       " \"isn't\": 361,\n",
       " 'da': 362,\n",
       " 'world': 363,\n",
       " 'dunno': 364,\n",
       " 'wow': 365,\n",
       " 'agree': 366,\n",
       " 'mom': 367,\n",
       " 'gotta': 368,\n",
       " 'makes': 369,\n",
       " 'without': 370,\n",
       " 'found': 371,\n",
       " 'lots': 372,\n",
       " 'everyone': 373,\n",
       " 'guitar': 374,\n",
       " 'country': 375,\n",
       " 'dvd': 376,\n",
       " 'ha': 377,\n",
       " 'times': 378,\n",
       " 'end': 379,\n",
       " \"won't\": 380,\n",
       " 'playing': 381,\n",
       " 'sucks': 382,\n",
       " 'anyway': 383,\n",
       " 'us': 384,\n",
       " 'book': 385,\n",
       " 'click': 386,\n",
       " 'f': 387,\n",
       " 'least': 388,\n",
       " 'house': 389,\n",
       " 'while': 390,\n",
       " 'happy': 391,\n",
       " 'comes': 392,\n",
       " 'came': 393,\n",
       " 'hair': 394,\n",
       " 'loved': 395,\n",
       " 'didnt': 396,\n",
       " 'doing': 397,\n",
       " 'win': 398,\n",
       " 'newer': 399,\n",
       " 'episode': 400,\n",
       " 'sings': 401,\n",
       " '6': 402,\n",
       " 'getting': 403,\n",
       " 'mine': 404,\n",
       " 'may': 405,\n",
       " 'tom': 406,\n",
       " 'watching': 407,\n",
       " 'activity': 408,\n",
       " 'suck': 409,\n",
       " 'young': 410,\n",
       " 'star': 411,\n",
       " 'totally': 412,\n",
       " 'school': 413,\n",
       " 'paris': 414,\n",
       " \"there's\": 415,\n",
       " 'harry': 416,\n",
       " 'coming': 417,\n",
       " 'different': 418,\n",
       " 'kid': 419,\n",
       " 'mail': 420,\n",
       " 'anymore': 421,\n",
       " 'watched': 422,\n",
       " 'radio': 423,\n",
       " 'dumb': 424,\n",
       " 'away': 425,\n",
       " 'goes': 426,\n",
       " 'night': 427,\n",
       " 'few': 428,\n",
       " 'boys': 429,\n",
       " 'means': 430,\n",
       " 'doubt': 431,\n",
       " 'family': 432,\n",
       " 'men': 433,\n",
       " 'series': 434,\n",
       " 'king': 435,\n",
       " 'played': 436,\n",
       " 'full': 437,\n",
       " 'myself': 438,\n",
       " 'tried': 439,\n",
       " 'ass': 440,\n",
       " 'info': 441,\n",
       " 'ebay': 442,\n",
       " 'white': 443,\n",
       " 'true': 444,\n",
       " 'club': 445,\n",
       " 'being': 446,\n",
       " 'trying': 447,\n",
       " 'place': 448,\n",
       " 'metal': 449,\n",
       " 'fav': 450,\n",
       " 'wanted': 451,\n",
       " 'asked': 452,\n",
       " 'start': 453,\n",
       " 'everything': 454,\n",
       " 'bit': 455,\n",
       " 'season': 456,\n",
       " 'stop': 457,\n",
       " 'whole': 458,\n",
       " 'die': 459,\n",
       " '8': 460,\n",
       " 'mind': 461,\n",
       " '9': 462,\n",
       " 'fall': 463,\n",
       " 'hit': 464,\n",
       " 'woman': 465,\n",
       " 'k': 466,\n",
       " 'days': 467,\n",
       " 'wife': 468,\n",
       " 'wish': 469,\n",
       " 'married': 470,\n",
       " 'rest': 471,\n",
       " 'bands': 472,\n",
       " 'list': 473,\n",
       " 'likes': 474,\n",
       " 'together': 475,\n",
       " 'brown': 476,\n",
       " 'm': 477,\n",
       " 'thanks': 478,\n",
       " 'punk': 479,\n",
       " 'plus': 480,\n",
       " 'y': 481,\n",
       " 'shows': 482,\n",
       " 'phone': 483,\n",
       " 'beat': 484,\n",
       " 'knew': 485,\n",
       " 'idol': 486,\n",
       " 'enough': 487,\n",
       " 'ones': 488,\n",
       " 'sex': 489,\n",
       " 'age': 490,\n",
       " 'yourself': 491,\n",
       " 'la': 492,\n",
       " 'dog': 493,\n",
       " 'film': 494,\n",
       " 'works': 495,\n",
       " 'sick': 496,\n",
       " 'having': 497,\n",
       " 'fat': 498,\n",
       " 'talk': 499,\n",
       " 'feel': 500,\n",
       " 'damn': 501,\n",
       " 'pay': 502,\n",
       " 'knows': 503,\n",
       " 'doesnt': 504,\n",
       " 'heart': 505,\n",
       " 'artist': 506,\n",
       " 'top': 507,\n",
       " 'crap': 508,\n",
       " 'looked': 509,\n",
       " 'nope': 510,\n",
       " 'park': 511,\n",
       " 'ive': 512,\n",
       " 'ipod': 513,\n",
       " 'done': 514,\n",
       " 'okay': 515,\n",
       " 'game': 516,\n",
       " 'second': 517,\n",
       " 'x': 518,\n",
       " 'seems': 519,\n",
       " 'definitely': 520,\n",
       " 'whatever': 521,\n",
       " 'dad': 522,\n",
       " 'answers': 523,\n",
       " 'sad': 524,\n",
       " 'joke': 525,\n",
       " 'sometimes': 526,\n",
       " 'word': 527,\n",
       " 'others': 528,\n",
       " 'asking': 529,\n",
       " 'part': 530,\n",
       " 'shes': 531,\n",
       " 'son': 532,\n",
       " 'ago': 533,\n",
       " 'g': 534,\n",
       " 'internet': 535,\n",
       " 'bet': 536,\n",
       " 'must': 537,\n",
       " 'women': 538,\n",
       " 'under': 539,\n",
       " 'almost': 540,\n",
       " \"you'll\": 541,\n",
       " 'high': 542,\n",
       " 'potter': 543,\n",
       " 'far': 544,\n",
       " 'pop': 545,\n",
       " 'unless': 546,\n",
       " 'um': 547,\n",
       " 'learn': 548,\n",
       " 'each': 549,\n",
       " 'cent': 550,\n",
       " 'web': 551,\n",
       " 'forget': 552,\n",
       " 'words': 553,\n",
       " 'blonde': 554,\n",
       " 'kill': 555,\n",
       " \"80's\": 556,\n",
       " 'hands': 557,\n",
       " 'saying': 558,\n",
       " 'player': 559,\n",
       " 'theres': 560,\n",
       " 'matter': 561,\n",
       " 'soon': 562,\n",
       " \"wasn't\": 563,\n",
       " 'especially': 564,\n",
       " 'picture': 565,\n",
       " 'beautiful': 566,\n",
       " 'easy': 567,\n",
       " 'until': 568,\n",
       " \"couldn't\": 569,\n",
       " 'kiss': 570,\n",
       " 'laugh': 571,\n",
       " 'vote': 572,\n",
       " 'hip': 573,\n",
       " 'write': 574,\n",
       " 'mr': 575,\n",
       " 'red': 576,\n",
       " 'thinking': 577,\n",
       " 'stand': 578,\n",
       " 'turn': 579,\n",
       " 'hop': 580,\n",
       " 'j': 581,\n",
       " 'none': 582,\n",
       " 'link': 583,\n",
       " 'version': 584,\n",
       " 'shot': 585,\n",
       " 'johnny': 586,\n",
       " 'gone': 587,\n",
       " 'sister': 588,\n",
       " 'wonder': 589,\n",
       " '7': 590,\n",
       " 'duh': 591,\n",
       " 'mad': 592,\n",
       " 'rocks': 593,\n",
       " 'listening': 594,\n",
       " 'helps': 595,\n",
       " 'heck': 596,\n",
       " 'wants': 597,\n",
       " 'close': 598,\n",
       " 'run': 599,\n",
       " 'brother': 600,\n",
       " 'story': 601,\n",
       " 'enjoy': 602,\n",
       " 'number': 603,\n",
       " 'line': 604,\n",
       " 'send': 605,\n",
       " 'tho': 606,\n",
       " 'three': 607,\n",
       " 'self': 608,\n",
       " 'coz': 609,\n",
       " 'fine': 610,\n",
       " 'em': 611,\n",
       " 'famous': 612,\n",
       " 'hand': 613,\n",
       " 'child': 614,\n",
       " 'luv': 615,\n",
       " 'eat': 616,\n",
       " 'drink': 617,\n",
       " 'chuck': 618,\n",
       " 'lost': 619,\n",
       " 'computer': 620,\n",
       " 'haha': 621,\n",
       " 'hi': 622,\n",
       " 'singing': 623,\n",
       " 'started': 624,\n",
       " 'havent': 625,\n",
       " 'dream': 626,\n",
       " 'eyes': 627,\n",
       " 'itunes': 628,\n",
       " 'face': 629,\n",
       " 'told': 630,\n",
       " 'cartoon': 631,\n",
       " 'date': 632,\n",
       " \"aren't\": 633,\n",
       " 'boring': 634,\n",
       " 'choose': 635,\n",
       " 'weird': 636,\n",
       " 'air': 637,\n",
       " 'store': 638,\n",
       " 'ppl': 639,\n",
       " 'super': 640,\n",
       " 'john': 641,\n",
       " 'worry': 642,\n",
       " 'h': 643,\n",
       " 'amazing': 644,\n",
       " 'english': 645,\n",
       " 'kelly': 646,\n",
       " 'clue': 647,\n",
       " 'pink': 648,\n",
       " 'actor': 649,\n",
       " 'group': 650,\n",
       " \"'\": 651,\n",
       " 'making': 652,\n",
       " 'classic': 653,\n",
       " 'half': 654,\n",
       " 'won': 655,\n",
       " 'sort': 656,\n",
       " 'shut': 657,\n",
       " 'kick': 658,\n",
       " 'worst': 659,\n",
       " 'cares': 660,\n",
       " 'chance': 661,\n",
       " 'aint': 662,\n",
       " 'knock': 663,\n",
       " 'ill': 664,\n",
       " 'father': 665,\n",
       " 'chick': 666,\n",
       " 'sweet': 667,\n",
       " 'title': 668,\n",
       " 'took': 669,\n",
       " 'jackson': 670,\n",
       " 'butt': 671,\n",
       " 'lil': 672,\n",
       " 'original': 673,\n",
       " 'paul': 674,\n",
       " 'blue': 675,\n",
       " 'fire': 676,\n",
       " 'car': 677,\n",
       " 'fake': 678,\n",
       " 'wit': 679,\n",
       " 'myspace': 680,\n",
       " 'spell': 681,\n",
       " 'jones': 682,\n",
       " 'greatest': 683,\n",
       " '2nd': 684,\n",
       " 'death': 685,\n",
       " 'party': 686,\n",
       " 'loves': 687,\n",
       " 'popular': 688,\n",
       " 'scary': 689,\n",
       " 'worth': 690,\n",
       " 'v': 691,\n",
       " 'sign': 692,\n",
       " 'videos': 693,\n",
       " 'online': 694,\n",
       " 'cry': 695,\n",
       " 'quite': 696,\n",
       " 'door': 697,\n",
       " 'usually': 698,\n",
       " 'omg': 699,\n",
       " \"ain't\": 700,\n",
       " 'killed': 701,\n",
       " 'bob': 702,\n",
       " 'couple': 703,\n",
       " 'reason': 704,\n",
       " 'umm': 705,\n",
       " 'needs': 706,\n",
       " 'imdb': 707,\n",
       " 'fly': 708,\n",
       " 'bar': 709,\n",
       " 'rich': 710,\n",
       " 'magazine': 711,\n",
       " 'although': 712,\n",
       " 'our': 713,\n",
       " 'stay': 714,\n",
       " 'wont': 715,\n",
       " 'himself': 716,\n",
       " 'brad': 717,\n",
       " 'simple': 718,\n",
       " 'problem': 719,\n",
       " 'michael': 720,\n",
       " 'jessica': 721,\n",
       " 'daughter': 722,\n",
       " 'female': 723,\n",
       " \"what's\": 724,\n",
       " 'isnt': 725,\n",
       " 'miss': 726,\n",
       " 'idiot': 727,\n",
       " 'move': 728,\n",
       " 'emo': 729,\n",
       " 'alive': 730,\n",
       " 'james': 731,\n",
       " 'point': 732,\n",
       " 'died': 733,\n",
       " 'bunch': 734,\n",
       " 'cannot': 735,\n",
       " 'exactly': 736,\n",
       " 'late': 737,\n",
       " 'id': 738,\n",
       " '20': 739,\n",
       " 'water': 740,\n",
       " 'david': 741,\n",
       " 'monkey': 742,\n",
       " 'everybody': 743,\n",
       " 'copy': 744,\n",
       " 'named': 745,\n",
       " 'above': 746,\n",
       " 'understand': 747,\n",
       " 'jack': 748,\n",
       " 'actress': 749,\n",
       " 'job': 750,\n",
       " 'news': 751,\n",
       " 'box': 752,\n",
       " 'through': 753,\n",
       " 'definately': 754,\n",
       " 'act': 755,\n",
       " 'using': 756,\n",
       " 'room': 757,\n",
       " 'walk': 758,\n",
       " 'chicken': 759,\n",
       " 'dirty': 760,\n",
       " 'yep': 761,\n",
       " 'email': 762,\n",
       " 'net': 763,\n",
       " 'george': 764,\n",
       " 'meet': 765,\n",
       " 'boyfriend': 766,\n",
       " 'husband': 767,\n",
       " 'books': 768,\n",
       " 'later': 769,\n",
       " 'somewhere': 770,\n",
       " '100': 771,\n",
       " 'z': 772,\n",
       " 'break': 773,\n",
       " 'deal': 774,\n",
       " 'joe': 775,\n",
       " \"you've\": 776,\n",
       " 'hilton': 777,\n",
       " '1st': 778,\n",
       " 'ah': 779,\n",
       " 'superman': 780,\n",
       " 'sooo': 781,\n",
       " 'beyonce': 782,\n",
       " 'happen': 783,\n",
       " 'bout': 784,\n",
       " 'hmm': 785,\n",
       " 'west': 786,\n",
       " 'beatles': 787,\n",
       " 'freak': 788,\n",
       " 'between': 789,\n",
       " 'pictures': 790,\n",
       " 'bought': 791,\n",
       " 'trust': 792,\n",
       " 'smart': 793,\n",
       " 'single': 794,\n",
       " 'seem': 795,\n",
       " '12': 796,\n",
       " 'fast': 797,\n",
       " 'afraid': 798,\n",
       " 'sites': 799,\n",
       " 'leave': 800,\n",
       " 'engine': 801,\n",
       " 'week': 802,\n",
       " 'lee': 803,\n",
       " '15': 804,\n",
       " 'ice': 805,\n",
       " 'wars': 806,\n",
       " 'huh': 807,\n",
       " 'road': 808,\n",
       " '18': 809,\n",
       " 'momma': 810,\n",
       " 'eminem': 811,\n",
       " 'christmas': 812,\n",
       " 'opinion': 813,\n",
       " 'mp3': 814,\n",
       " 'finally': 815,\n",
       " 'sang': 816,\n",
       " 'smith': 817,\n",
       " 'born': 818,\n",
       " 'scene': 819,\n",
       " 'bass': 820,\n",
       " 'space': 821,\n",
       " 'cruise': 822,\n",
       " 'mike': 823,\n",
       " 'jokes': 824,\n",
       " 'whats': 825,\n",
       " 'open': 826,\n",
       " 'become': 827,\n",
       " 'channel': 828,\n",
       " 'l': 829,\n",
       " 'louie': 830,\n",
       " \"who's\": 831,\n",
       " 'older': 832,\n",
       " 'body': 833,\n",
       " 'perfect': 834,\n",
       " 'mtv': 835,\n",
       " 'amazon': 836,\n",
       " 'daddy': 837,\n",
       " 'cat': 838,\n",
       " 'fight': 839,\n",
       " 'ways': 840,\n",
       " 'plays': 841,\n",
       " 'working': 842,\n",
       " \"here's\": 843,\n",
       " 'city': 844,\n",
       " '30': 845,\n",
       " 'burn': 846,\n",
       " 'annoying': 847,\n",
       " 'dark': 848,\n",
       " 'april': 849,\n",
       " 'mostly': 850,\n",
       " 'station': 851,\n",
       " 'kong': 852,\n",
       " 'lucky': 853,\n",
       " 'wolf': 854,\n",
       " 'norris': 855,\n",
       " 'queen': 856,\n",
       " 'nobody': 857,\n",
       " 'add': 858,\n",
       " 'forgot': 859,\n",
       " 'twice': 860,\n",
       " 'third': 861,\n",
       " 'tonight': 862,\n",
       " 'pants': 863,\n",
       " 'today': 864,\n",
       " 'york': 865,\n",
       " 'heavy': 866,\n",
       " 'idk': 867,\n",
       " 'figure': 868,\n",
       " 'lady': 869,\n",
       " 'linkin': 870,\n",
       " 'games': 871,\n",
       " 'theme': 872,\n",
       " '24': 873,\n",
       " 'able': 874,\n",
       " 'simpson': 875,\n",
       " 'office': 876,\n",
       " 'girlfriend': 877,\n",
       " 'gave': 878,\n",
       " 'dat': 879,\n",
       " 'hilarious': 880,\n",
       " 'count': 881,\n",
       " 'shit': 882,\n",
       " 'concert': 883,\n",
       " 'mother': 884,\n",
       " 'small': 885,\n",
       " 'children': 886,\n",
       " 'personally': 887,\n",
       " 'awsome': 888,\n",
       " '11': 889,\n",
       " 'taylor': 890,\n",
       " 'bearshare': 891,\n",
       " 'vegas': 892,\n",
       " 'metallica': 893,\n",
       " 'mary': 894,\n",
       " 'street': 895,\n",
       " 'drunk': 896,\n",
       " 'batman': 897,\n",
       " 'illegal': 898,\n",
       " 'wat': 899,\n",
       " 'months': 900,\n",
       " 'websites': 901,\n",
       " 'rather': 902,\n",
       " 'record': 903,\n",
       " \"you'd\": 904,\n",
       " 'kno': 905,\n",
       " 'minutes': 906,\n",
       " 'prefer': 907,\n",
       " 'broke': 908,\n",
       " 'britney': 909,\n",
       " 'absolutely': 910,\n",
       " 'jolie': 911,\n",
       " '13': 912,\n",
       " 'special': 913,\n",
       " 'wrote': 914,\n",
       " 'disney': 915,\n",
       " 'quit': 916,\n",
       " 'ace': 917,\n",
       " 'obviously': 918,\n",
       " 'uh': 919,\n",
       " 'brothers': 920,\n",
       " 'style': 921,\n",
       " 'kevin': 922,\n",
       " 'depp': 923,\n",
       " 'huge': 924,\n",
       " 'talent': 925,\n",
       " 'whoa': 926,\n",
       " 'anyways': 927,\n",
       " 'male': 928,\n",
       " 'don': 929,\n",
       " 'order': 930,\n",
       " 'interesting': 931,\n",
       " 'floyd': 932,\n",
       " 'hottest': 933,\n",
       " 'bring': 934,\n",
       " 'bow': 935,\n",
       " \"cd's\": 936,\n",
       " 'mama': 937,\n",
       " \"'em\": 938,\n",
       " 'post': 939,\n",
       " '2006': 940,\n",
       " 'eye': 941,\n",
       " 'marry': 942,\n",
       " 'dr': 943,\n",
       " 'daniel': 944,\n",
       " 'dreams': 945,\n",
       " 'hurt': 946,\n",
       " 'area': 947,\n",
       " 'jesus': 948,\n",
       " 'guns': 949,\n",
       " 'elvis': 950,\n",
       " 'missed': 951,\n",
       " 'page': 952,\n",
       " 'nick': 953,\n",
       " 'instead': 954,\n",
       " 'couldnt': 955,\n",
       " 'happened': 956,\n",
       " 'jay': 957,\n",
       " 'except': 958,\n",
       " 'sky': 959,\n",
       " '14': 960,\n",
       " 'dancing': 961,\n",
       " 'taste': 962,\n",
       " 'slow': 963,\n",
       " 'along': 964,\n",
       " 'mouth': 965,\n",
       " 'dave': 966,\n",
       " 'lord': 967,\n",
       " 'stick': 968,\n",
       " 'lets': 969,\n",
       " 'drive': 970,\n",
       " 'kidding': 971,\n",
       " 'blood': 972,\n",
       " 'stars': 973,\n",
       " 'soooo': 974,\n",
       " 'america': 975,\n",
       " 'singers': 976,\n",
       " 'supposed': 977,\n",
       " 'sleep': 978,\n",
       " 'character': 979,\n",
       " 'south': 980,\n",
       " '>': 981,\n",
       " 'waste': 982,\n",
       " 'soul': 983,\n",
       " 'hehe': 984,\n",
       " 'lame': 985,\n",
       " 'cheap': 986,\n",
       " 'model': 987,\n",
       " 'fish': 988,\n",
       " 'media': 989,\n",
       " 'paid': 990,\n",
       " 'favorites': 991,\n",
       " 'busy': 992,\n",
       " 'birthday': 993,\n",
       " 'hilary': 994,\n",
       " 'duff': 995,\n",
       " 'thinks': 996,\n",
       " 'u2': 997,\n",
       " 'fell': 998,\n",
       " 'section': 999,\n",
       " 'reading': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units= 1024\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
    "\n",
    "train = tf.data.Dataset.from_tensor_slices((input_train, target_train)).shuffle(BUFFER_SIZE)\n",
    "train = train.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 32]), TensorShape([64, 43]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(train))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder_units = encoder_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.encoder_units,\n",
    "                                       return_sequences=True, \n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size, self.encoder_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_vocab_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tokenizer.word_index['with']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, decoder_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.decoder_units = decoder_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.decoder_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        self.attention = BahdanauAttention(self.decoder_units)\n",
    "        \n",
    "    def call(self, x, hidden, encoder_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, encoder_output)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(target_vocab_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "static_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss = static_loss(real, pred)\n",
    "     \n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inpt, trgt, enc_hidden):\n",
    "    loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inpt, enc_hidden)\n",
    "        \n",
    "        dec_hidden = enc_hidden\n",
    "        \n",
    "        dec_input = tf.expand_dims([target_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "        \n",
    "        for t in range(1, trgt.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(trgt[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(trgt[:, t], 1)\n",
    "            \n",
    "        batch_loss = loss / int(trgt.shape[1])\n",
    "        \n",
    "        variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "        \n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        \n",
    "        return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training-checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-6b63c9dc70d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    start = datetime.now()\n",
    "    \n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (inpt, trgt)) in enumerate(train.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inpt, trgt, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch+1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.numpy()))\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "            \n",
    "        print('Epoch {} Loss {:.4f}'.format(epoch+1,\n",
    "                                            total_loss/steps_per_epoch))\n",
    "        print('Time taken for 1 epoch {} seconds\\n'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
