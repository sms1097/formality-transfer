{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Tagging for Formality Transfer\n",
    "This will learn how to tag parts of speech and tag on the sequences. The parts of speech and the sequence will be fed into two separate encoders and then concatenated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "import nltk\n",
    "import re \n",
    "\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite import scorers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '../../Data'\n",
    "\n",
    "FORMAL_PATH_TRAIN = '{}/Supervised Data/Entertainment_Music/S_Formal_EM_Train.txt'.format(BASE_PATH)\n",
    "INFORMAL_PATH_TRAIN = '{}/Supervised Data/Entertainment_Music/S_Informal_EM_Train.txt'.format(BASE_PATH)\n",
    "\n",
    "FORMAL_PATH_HOLDOUT = '{}/Supervised Data/Entertainment_Music/S_Formal_EM_ValTest.txt'.format(BASE_PATH)\n",
    "INFORMAL_PATH_HOLDOUT = '{}/Supervised Data/Entertainment_Music/S_Informal_EM_ValTest.txt'.format(BASE_PATH)\n",
    "\n",
    "POS_TRAIN_PATH = BASE_PATH + '/POS Data/pos.train.txt'\n",
    "POS_TEST_PATH = BASE_PATH + '/POS Data/pos.test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "x6EaDkEtMOUA"
   },
   "outputs": [],
   "source": [
    "formal = open(FORMAL_PATH_TRAIN).read()\n",
    "informal = open(INFORMAL_PATH_TRAIN).read()\n",
    "\n",
    "formal_holdout = open(FORMAL_PATH_HOLDOUT).read()\n",
    "informal_holdout = open(INFORMAL_PATH_HOLDOUT).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "6_pLPgB0MOUA"
   },
   "outputs": [],
   "source": [
    "if_corpus = [seq.split() for seq in informal.split('\\n')]\n",
    "\n",
    "if_holdout = [seq.split() for seq in informal_holdout.split('\\n')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load POS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 training sequences\n",
      "914 testing sequence\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "\n",
    "train_data = treebank.tagged_sents()[:3000]  \n",
    "test_data = treebank.tagged_sents()[3000:]\n",
    "\n",
    "print('{} training sequences'.format(len(train_data)))\n",
    "print('{} testing sequence'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i, corpus=False):\n",
    "    if not corpus:\n",
    "        word = sent[i][0]\n",
    "\n",
    "        features = {\n",
    "            'prefix3': word[:3],\n",
    "            'prefix2': word[:2],\n",
    "            'prefix1': word[:1],\n",
    "            'suffix1': word[-1:],\n",
    "            'suffix2': word[-2:],\n",
    "            'suffix3': word[-3:],\n",
    "            'prev_word': '' if i == 0 else sent[i-1][0],\n",
    "            'next_word': '' if i == len(sent) - 1 else sent[i+1][0],\n",
    "            'first': i == 0,\n",
    "            'last': i == len(sent) - 1\n",
    "        }\n",
    "    else:\n",
    "        word = sent[i]\n",
    "        features = {\n",
    "            'prefix3': word[:3],\n",
    "            'prefix2': word[:2],\n",
    "            'prefix1': word[:1],\n",
    "            'suffix1': word[-1:],\n",
    "            'suffix2': word[-2:],\n",
    "            'suffix3': word[-3:],\n",
    "            'prev_word': '' if i == 0 else sent[i-1],\n",
    "            'next_word': '' if i == len(sent) - 1 else sent[i+1],\n",
    "            'first': i == 0,\n",
    "            'last': i == len(sent) - 1\n",
    "        }\n",
    "    \n",
    "    return features\n",
    "\n",
    "def sent2features(sent, corpus=False):\n",
    "    return [word2features(sent, i, corpus) for i in range(len(sent))]\n",
    "\n",
    "def sent2pos(sent):\n",
    "    return [pos for _, pos in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(seq) for seq in train_data] \n",
    "y_train = [sent2pos(seq) for seq in train_data]\n",
    "\n",
    "X_test = [sent2features(seq) for seq in train_data]\n",
    "y_test = [sent2pos(seq) for seq in train_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    keep_tempfiles=None, max_iterations=100)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=['#', '$', ',', '.', ':', \"''\", 'RB', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'RBR', 'RBS', 'VBZ', 'CC', 'CD', 'MD', 'PDT', 'WDT', 'UH', 'JJ', 'JJR', 'JJS', '-LRB-', 'IN', 'NN', '-NONE-', 'NNP', 'NNPS', 'NNS', 'TO', 'POS', 'RP', 'WP', 'WP$', 'WRB', 'PRP', 'PRP$', '-RRB-', 'LS', 'DT', 'FW', 'EX', 'SYM', '``'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/home/sean/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           #      1.000     1.000     1.000        13\n",
      "           $      1.000     1.000     1.000       469\n",
      "           ,      1.000     1.000     1.000      3780\n",
      "           .      1.000     1.000     1.000      2983\n",
      "           :      1.000     1.000     1.000       482\n",
      "          ''      1.000     1.000     1.000       602\n",
      "          RB      0.980     0.974     0.977      2277\n",
      "          VB      0.990     0.988     0.989      2004\n",
      "         VBD      0.989     0.986     0.987      2139\n",
      "         VBG      0.976     0.988     0.982      1154\n",
      "         VBN      0.976     0.986     0.981      1612\n",
      "         VBP      0.985     0.987     0.986      1144\n",
      "         RBR      0.982     0.915     0.947       118\n",
      "         RBS      1.000     0.966     0.982        29\n",
      "         VBZ      0.997     0.997     0.997      1767\n",
      "          CC      0.995     1.000     0.997      1762\n",
      "          CD      0.997     0.998     0.998      2338\n",
      "          MD      1.000     1.000     1.000       702\n",
      "         PDT      0.955     1.000     0.977        21\n",
      "         WDT      0.994     1.000     0.997       325\n",
      "          UH      1.000     1.000     1.000         3\n",
      "          JJ      0.976     0.958     0.967      4551\n",
      "         JJR      0.963     0.990     0.976       287\n",
      "         JJS      0.993     1.000     0.996       140\n",
      "       -LRB-      1.000     1.000     1.000        88\n",
      "          IN      0.993     0.995     0.994      7559\n",
      "          NN      0.984     0.987     0.986      9846\n",
      "      -NONE-      1.000     1.000     1.000      5089\n",
      "         NNP      0.996     0.997     0.997      7292\n",
      "        NNPS      0.981     0.927     0.953       165\n",
      "         NNS      0.995     0.998     0.996      4715\n",
      "          TO      0.999     1.000     1.000      1660\n",
      "         POS      1.000     1.000     1.000       597\n",
      "          RP      0.938     0.917     0.927       181\n",
      "          WP      1.000     1.000     1.000       215\n",
      "         WP$      1.000     1.000     1.000        10\n",
      "         WRB      1.000     1.000     1.000       148\n",
      "         PRP      0.999     0.999     0.999      1471\n",
      "        PRP$      0.998     0.998     0.998       633\n",
      "       -RRB-      1.000     1.000     1.000        94\n",
      "          LS      1.000     1.000     1.000        13\n",
      "          DT      0.998     0.999     0.999      6334\n",
      "          FW      1.000     1.000     1.000         4\n",
      "          EX      1.000     1.000     1.000        77\n",
      "         SYM      0.000     0.000     0.000         1\n",
      "          ``      1.000     1.000     1.000       617\n",
      "\n",
      "    accuracy                          0.992     77511\n",
      "   macro avg      0.970     0.968     0.969     77511\n",
      "weighted avg      0.992     0.992     0.992     77511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    crf.classes_,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_input = [sent2features(seq, True) for seq in if_corpus]\n",
    "if_hol_pos = [sent2features(seq, True) for seq in if_holdout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = crf.predict(if_input)\n",
    "holdout_preds = crf.predict(if_hol_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('S_Informal_EM_Train_POS.txt', 'w') as f:\n",
    "    for seq in train_preds:\n",
    "        f.write(' '.join(seq) + '\\n')\n",
    "\n",
    "with open('S_Informal_EM_ValTest_POS.txt', 'w') as f:\n",
    "    for seq in holdout_preds:\n",
    "        f.write(' '.join(seq) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
