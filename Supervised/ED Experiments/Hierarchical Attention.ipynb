{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Attention Model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WZnAymJMOT-"
      },
      "source": [
        "# Rule Assisted Concat with Global Attention\n",
        "This is a fancy name for a seq2seq network with multiple encoders. These use some prebuilt rules that are as follows:\n",
        "1. Capitalize the first word\n",
        "2. Lowercase words that are all upper case\n",
        "3. Expand contractions\n",
        "4. Replace Slang words\n",
        "5. Replace Swear words\n",
        "6. Replace repeated characters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXSULbTAck6K"
      },
      "source": [
        "For the hierarchical approach we have two sequences: $x$ and $x^\\prime$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZpo0DbmMOT_"
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "import re \n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIh8TGdFMOT_"
      },
      "source": [
        "### Declare Static Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLWD_vDUMUbK",
        "outputId": "9783c507-a32b-40b0-b419-d71655fe1325"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiCo7jwJMOT_"
      },
      "source": [
        "These parameters are mostly stolen from the Google Paper, except for embedding dim which is determined from GloVE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgjKj15QMOT_"
      },
      "source": [
        "EMBEDDING_DIM = 200\n",
        "ATTENTION_UNITS = 512\n",
        "ENCODER_UNITS = 1024\n",
        "DECODER_UNITS = 1024\n",
        "BATCH_SIZE = 64\n",
        "MAX_INPUT_LENGTH = 32"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9sTDg2lMOT_"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzSYxc4yMOT_"
      },
      "source": [
        "BASE_PATH = '/content/drive/MyDrive/Data/Data'  # on local is path to directory\n",
        "# BASE_PATH = '../../Data'\n",
        "\n",
        "FORMAL_PATH_TRAIN = '{}/Supervised Data/Entertainment_Music/S_Formal_EM_Train.txt'.format(BASE_PATH)\n",
        "INFORMAL_PATH_TRAIN = '{}/Supervised Data/Entertainment_Music/S_Informal_EM_Train.txt'.format(BASE_PATH)\n",
        "\n",
        "FORMAL_PATH_HOLDOUT = '{}/Supervised Data/Entertainment_Music/S_Formal_EM_ValTest.txt'.format(BASE_PATH)\n",
        "INFORMAL_PATH_HOLDOUT = '{}/Supervised Data/Entertainment_Music/S_Informal_EM_ValTest.txt'.format(BASE_PATH)\n",
        "\n",
        "CONTRACTIONS_PATH = '{}/Rule Data/Contractions.txt'.format(BASE_PATH)\n",
        "SLANG_PATH = '{}/Rule Data/Slang.txt'.format(BASE_PATH)\n",
        "SWEARS_PATH = '{}/Rule Data/Swears.csv'.format(BASE_PATH)\n",
        "\n",
        "EMBEDDING_PATH = '{}/glove.6B.200d.txt'.format(BASE_PATH)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6EaDkEtMOUA"
      },
      "source": [
        "formal = open(FORMAL_PATH_TRAIN).read()\n",
        "informal = open(INFORMAL_PATH_TRAIN).read()\n",
        "\n",
        "formal_holdout = open(FORMAL_PATH_HOLDOUT).read()\n",
        "informal_holdout = open(INFORMAL_PATH_HOLDOUT).read()"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fenTZWMxMOUA"
      },
      "source": [
        "def process_sequence(seq):\n",
        "    \"\"\"This inserts a space in between the last word and a period\"\"\"\n",
        "    s = re.sub('([.,!?()])', r' \\1 ', seq)\n",
        "    s = re.sub('\\s{2,}', ' ', s)\n",
        "    \n",
        "    return '<start> ' + s + ' <end>'"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_pLPgB0MOUA"
      },
      "source": [
        "f_corpus = [process_sequence(seq) for seq in formal.split('\\n')]\n",
        "if_corpus = [process_sequence(seq) for seq in informal.split('\\n')]\n",
        "\n",
        "f_holdout = [process_sequence(seq) for seq in formal_holdout.split('\\n')]\n",
        "if_holdout = [process_sequence(seq) for seq in informal_holdout.split('\\n')]"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkN39M_qck6K"
      },
      "source": [
        "### Load slang and Contractions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC7iHUueck6K"
      },
      "source": [
        "import csv\n",
        "cont = []\n",
        "cont_corr = []\n",
        "\n",
        "slang = []\n",
        "slang_corr = []\n",
        "\n",
        "swears = []\n",
        "with open(CONTRACTIONS_PATH, 'r') as f:\n",
        "    for line in csv.reader(f, dialect='excel-tab'):\n",
        "        cont.append(line[0])\n",
        "        cont_corr.append(line[1])\n",
        "        \n",
        "with open(SLANG_PATH) as f:\n",
        "    for line in csv.reader(f, dialect='excel-tab'):\n",
        "        slang.append(line[0])\n",
        "        slang_corr.append(line[1])\n",
        "        \n",
        "with open(SWEARS_PATH) as f:\n",
        "    for line in csv.reader(f):\n",
        "        swears.append(line)\n",
        "swears = swears[0]"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ55lZV3ck6K"
      },
      "source": [
        "### Apply Rules\n",
        "1. Capitalize the first word\n",
        "2. Lowercase words that are all upper case\n",
        "3. Expand contractions\n",
        "4. Replace Slang words\n",
        "5. Replace Swear words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXTFzrX_ck6K"
      },
      "source": [
        "def rule(seqs):\n",
        "    out = []\n",
        "    for seq in seqs:\n",
        "        curr_seq = seq.split()\n",
        "        temp = []\n",
        "        \n",
        "        for i, word in enumerate(curr_seq):\n",
        "            curr_word = word\n",
        "            \n",
        "            if i == 1:\n",
        "                curr_word = curr_word.capitalize()\n",
        "            \n",
        "            if curr_word == curr_word.upper():\n",
        "                curr_word = curr_word.lower()\n",
        "                \n",
        "            if curr_word in slang:\n",
        "                curr_word = slang_corr[slang.index(curr_word)]\n",
        "                \n",
        "            if curr_word in swears:\n",
        "                curr_word = curr_word[0] + '*' * (len(curr_word) - 2)\n",
        "            \n",
        "            temp.append(curr_word)\n",
        "                \n",
        "        out.append(' '.join(temp))  \n",
        "    return out"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCrQj9dxck6K"
      },
      "source": [
        "x_prime_raw = rule(if_corpus)\n",
        "x_prime_holdout = rule(if_holdout)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuet6JWVMOUA"
      },
      "source": [
        "### Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czog7VXRMOUA"
      },
      "source": [
        "def tokenize(corpus, tokenizer=None, maxlen=None):\n",
        "    \"\"\" Tokenize data and pad sequences \"\"\"\n",
        "    if not tokenizer: \n",
        "        tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', \n",
        "                              oov_token='<OOV>', lower=False)\n",
        "        tokenizer.fit_on_texts(corpus)\n",
        "    \n",
        "    seqs = tokenizer.texts_to_sequences(corpus)\n",
        "    padded_seqs = pad_sequences(seqs, padding='post', maxlen=maxlen)\n",
        "\n",
        "    return padded_seqs, tokenizer"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8gCiXWAMOUA"
      },
      "source": [
        "input_train, input_tokenizer = tokenize(if_corpus)\n",
        "input_prime, _ = tokenize(x_prime_raw, input_tokenizer)\n",
        "target_train, target_tokenizer = tokenize(f_corpus)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROQQKO8uMOUA"
      },
      "source": [
        "input_test, _ = tokenize(if_holdout, input_tokenizer)\n",
        "primt_test, _ = tokenize(x_prime_holdout, input_tokenizer)\n",
        "target_test, _ = tokenize(f_holdout, target_tokenizer)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJpBO_F9MOUA"
      },
      "source": [
        "buffer_size = len(input_train)\n",
        "steps_per_epoch = len(input_train) // BATCH_SIZE\n",
        "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
        "\n",
        "train = tf.data.Dataset.from_tensor_slices((input_train, input_prime, target_train)).shuffle(buffer_size)\n",
        "train = train.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "test = tf.data.Dataset.from_tensor_slices((input_test, primt_test, target_test)).batch(1)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua_l1fZEMOUA"
      },
      "source": [
        "example_input_batch, example_prime_batch, example_target_batch = next(iter(train))"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSCRTB5PjmvD"
      },
      "source": [
        "# Setup Embedding Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enju-_z_p9u7"
      },
      "source": [
        "def embedding_matrix(tokenizer, vocab_size, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(EMBEDDING_PATH) as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "\n",
        "    embeddings_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in tokenizer.word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embeddings_matrix[i] = embedding_vector\n",
        "\n",
        "    return embeddings_matrix"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovQqc3ibqVj6"
      },
      "source": [
        "enc_E_mat = embedding_matrix(input_tokenizer, input_vocab_size, EMBEDDING_DIM)\n",
        "enc_E_mat_prime = embedding_matrix(input_tokenizer, input_vocab_size, EMBEDDING_DIM)\n",
        "dec_E_mat = embedding_matrix(target_tokenizer, target_vocab_size, EMBEDDING_DIM)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pv7RI8NMOUA"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dVMrge8kBd3"
      },
      "source": [
        "Using one bidirectional LSTMs because that was reported to get almost as good performance as 2 LSTMs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiW3IKWKMOUA"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, encoder_units, weight_matrix):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.encoder_units = encoder_units\n",
        "        if weight_matrix is not None:\n",
        "            self.embedding = tf.keras.layers.Embedding(vocab_size, \n",
        "                                                       embedding_dim,\n",
        "                                                       weights=[weight_matrix])\n",
        "        else:\n",
        "            self.embedding = tf.keras.layers.Embedding(vocab_size, \n",
        "                                                       embedding_dim)           \n",
        "        self.lstm_1 = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(\n",
        "                self.encoder_units,\n",
        "                return_sequences=True,\n",
        "                return_state=False\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.lstm_2 = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(\n",
        "                self.encoder_units,\n",
        "                return_sequences=True,\n",
        "                return_state=True\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def call(self, x, hidden_state):\n",
        "        \"\"\"Shove into latent space\"\"\"\n",
        "        # x shape: (batch_size x max_length x embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # output shape: (batch_size x max_length x 2 * encoder_units)\n",
        "        # h_f, h_b shapes: (batch_size x encoder_units)\n",
        "        output = self.lstm_1(x, initial_state=hidden_state)\n",
        "\n",
        "        output, h_f, _, _, _ = self.lstm_2(output)\n",
        "\n",
        "        return output, h_f "
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjpvfT3XMOUA"
      },
      "source": [
        "encoder = Encoder(input_vocab_size, EMBEDDING_DIM, ENCODER_UNITS, enc_E_mat)\n",
        "\n",
        "encoder_prime = Encoder(input_vocab_size, EMBEDDING_DIM, ENCODER_UNITS, None)\n",
        "\n",
        "init_state = [tf.zeros((BATCH_SIZE, ENCODER_UNITS)) for _ in range(4)]\n",
        "\n",
        "sample_output, hidden = encoder(example_input_batch, \n",
        "                                init_state)\n",
        "prime_output, hidden_prime = encoder_prime(example_prime_batch, \n",
        "                                          init_state)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc0BAr9pMOUA"
      },
      "source": [
        "### Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP5YEjIOMOUA"
      },
      "source": [
        "class GlobalAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    This is actually global attention from Luong, \n",
        "    it ignors the hidden backward state\n",
        "    \"\"\"\n",
        "    def __init__(self, units):\n",
        "        \"\"\"These parameters follow notation from Bahdanau paper\"\"\"\n",
        "        super(GlobalAttention, self).__init__()\n",
        "        self.W = tf.keras.layers.Dense(units)\n",
        "        self.U = tf.keras.layers.Dense(units)\n",
        "        self.v = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, enc_opt, hidden):\n",
        "        # expand dims to meet shape of latent tensor\n",
        "        # hidden_broad shape: (batch_size, 1, encoder_units)\n",
        "        hidden_broad = tf.expand_dims(hidden, 1)\n",
        "\n",
        "        # Alignment model score from A.1.2 of Bahdanau et al \n",
        "        # score shape: (batch_size, max_length, v_units)\n",
        "        score = self.v(tf.nn.tanh(self.W(hidden_broad) + self.U(enc_opt)))\n",
        "\n",
        "        # softmax generalization of eq(7) Luong\n",
        "        # attention_weights shape: (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)  \n",
        "\n",
        "        # This takes weighted average with attention weights\n",
        "        # context shape: (batch_size, 2 * encoder_units)\n",
        "        context = attention_weights * enc_opt\n",
        "        context = tf.reduce_sum(context, axis=1)\n",
        "\n",
        "        return context "
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7q_BYLQMOUA"
      },
      "source": [
        "attention_layer = GlobalAttention(ATTENTION_UNITS)\n",
        "attention_result = attention_layer(sample_output, \n",
        "                                   hidden)\n",
        "attention_prime = attention_layer(prime_output,\n",
        "                                  hidden_prime)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBwfe07qMOUA"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-RvXiF1MOUA"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, attention_units, \n",
        "                 decoder_units, batch_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.attention = GlobalAttention(attention_units)\n",
        "        self.attention_prime = GlobalAttention(attention_units)\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm_1 = tf.keras.layers.LSTM(decoder_units,\n",
        "                                           return_sequences=True,\n",
        "                                           return_state=True)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.W = tf.keras.layers.Dense(2 * ENCODER_UNITS)\n",
        "        self.opt = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, x, hidden, hidden_prime, encoder_output, prime_output, dec_hidden_forward):\n",
        "        # output shape: (BATCH_SIZE x MAX_LENGTH x 4 * ENCODER_UNITS)\n",
        "        output = tf.concat([encoder_output, prime_output], axis=-1)\n",
        "\n",
        "        # hidden shape: (BATHC_SIZE x 2 * ENCODER_UNITS)\n",
        "        hidden = tf.concat([hidden, hidden_prime], axis=-1)\n",
        "        \n",
        "        # context_vector shape: (batch_size, 2 * encoder_units)\n",
        "        context_vector = self.attention(output, hidden)\n",
        "\n",
        "        # x shape: (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # x shape: (batch_size, 1, embedding_dim + 2 * encoder_units)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "        # output shape: (batch_size, 1, decoder_units)\n",
        "        # this shape is only important for expanding decoder depth\n",
        "        output, h_f, _ = self.lstm_1(x)\n",
        "\n",
        "        # flatten to feed into opt\n",
        "        # output shape: (batch_size, hidden_size)\n",
        "        output = self.flatten(output)\n",
        "\n",
        "        # get logits\n",
        "        # x shape: (batch_size, vocab)\n",
        "        x = self.opt(output)\n",
        "\n",
        "        return x, h_f"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D1LdlK-MOUA"
      },
      "source": [
        "decoder = Decoder(target_vocab_size, EMBEDDING_DIM, ATTENTION_UNITS, \n",
        "                  DECODER_UNITS, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_input = tf.expand_dims([target_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "dec_hidden_forward = tf.zeros((64, ENCODER_UNITS))\n",
        "\n",
        "sample_decoder_output, aa = decoder(sample_decoder_input, hidden, hidden_prime, \n",
        "                                   sample_output, prime_output, dec_hidden_forward)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0P04Qa_MOUA"
      },
      "source": [
        "### Optimizer and Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unPfCctsMOUA"
      },
      "source": [
        "Here we define the optimizer and the loss function. In our loss function we mask the zeros since that's the padding.\n",
        "\n",
        "Also of note is in the loss function. The reduction argument at default does some really wonky things which threw off all results. Had to change the reduciton to none, which at default is auto. Not exactly sure what it does in this context but it tries to sum over batches. I didn't work with it because I wanted to control all loss calculation manually. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kis6sBiBMOUA"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "static_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnIepemQMOUA"
      },
      "source": [
        "def loss_function(real, preds):\n",
        "    \"\"\"Calculate and return loss\"\"\"\n",
        "\n",
        "    # caclulate loss\n",
        "    loss = static_loss(real, preds)\n",
        "    \n",
        "    # create padding mask \n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    \n",
        "    # apply mask\n",
        "    loss *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lzJ5Y0gMOUB"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOLvx7ygrMtv"
      },
      "source": [
        "This is the training loop. I'm using teacher forcing because I don't think I have enough computational power to use beam search. Google reccomends beam search with a beam width of 10, but that isn't an option here. Teacher forcing will provide better results than without using it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV21GU90MOUB"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inpt, prime, trgt, init_state):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, hidden = encoder(inpt, \n",
        "                                     init_state)\n",
        "        prime_output, hidden_prime = encoder_prime(prime, \n",
        "                                                   init_state)\n",
        "        # Get start token for every sequence in batch\n",
        "        dec_input = tf.expand_dims([target_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "        \n",
        "        dec_hidden_forward = tf.zeros((BATCH_SIZE, ENCODER_UNITS))\n",
        "\n",
        "        for i in range(1, trgt.shape[1]):\n",
        "            # dec_hidden shape: (batch_size, decoder_units)\n",
        "            # dec_input shape: (batch_size, 1)\n",
        "            predictions, dec_hidden_forward = decoder(dec_input, hidden, hidden_prime, \n",
        "                                                      enc_output, prime_output, dec_hidden_forward)\n",
        "                                                         \n",
        "            loss += loss_function(trgt[:, i], predictions)\n",
        "            dec_input = tf.expand_dims(trgt[:, 1], 1)\n",
        "\n",
        "        # Apply gradients \n",
        "        trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "\n",
        "        # return batch loss\n",
        "        return loss"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAjVsG1RLRYK",
        "outputId": "e7407da4-2657-4ba9-99d5-cfcff614b8d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoder.load_weights(BASE_PATH + '/Model Weights/Rule-Assisted/encoder')\n",
        "encoder_prime.load_weights(BASE_PATH + '/Model Weights/Rule-Assisted/encoder_prime')\n",
        "decoder.load_weights(BASE_PATH + '/Model Weights/Rule-Assisted/decoder')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f489025beb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXRvBFyOMOUB",
        "outputId": "99a2468d-fdc0-4231-ecf4-7a030fd608ad"
      },
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = datetime.now()\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    # This resets the hidden state of the LSTM for every epoch\n",
        "    init_state = [tf.zeros((BATCH_SIZE, ENCODER_UNITS)) for _ in range(4)]\n",
        "\n",
        "    for inpt, prime, trgt in train.take(steps_per_epoch):\n",
        "        total_loss += train_step(inpt, prime, trgt, init_state)\n",
        "\n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                        total_loss / BATCH_SIZE))\n",
        "    print('Time taken {}\\n'.format(datetime.now() - start))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 276.4538\n",
            "Time taken 0:02:45.801963\n",
            "\n",
            "Epoch 2 Loss 272.6833\n",
            "Time taken 0:02:46.147221\n",
            "\n",
            "Epoch 3 Loss 269.2672\n",
            "Time taken 0:02:46.186608\n",
            "\n",
            "Epoch 4 Loss 265.8460\n",
            "Time taken 0:02:45.872715\n",
            "\n",
            "Epoch 5 Loss 262.6496\n",
            "Time taken 0:02:46.098787\n",
            "\n",
            "Epoch 6 Loss 259.5744\n",
            "Time taken 0:02:46.005524\n",
            "\n",
            "Epoch 7 Loss 256.4969\n",
            "Time taken 0:02:46.225745\n",
            "\n",
            "Epoch 8 Loss 253.7922\n",
            "Time taken 0:02:46.078150\n",
            "\n",
            "Epoch 9 Loss 250.9256\n",
            "Time taken 0:02:46.368682\n",
            "\n",
            "Epoch 10 Loss 248.2212\n",
            "Time taken 0:02:46.153584\n",
            "\n",
            "Epoch 11 Loss 245.5357\n",
            "Time taken 0:02:46.418215\n",
            "\n",
            "Epoch 12 Loss 243.1682\n",
            "Time taken 0:02:46.304968\n",
            "\n",
            "Epoch 13 Loss 240.7848\n",
            "Time taken 0:02:46.506083\n",
            "\n",
            "Epoch 14 Loss 238.2824\n",
            "Time taken 0:02:46.397549\n",
            "\n",
            "Epoch 15 Loss 235.9997\n",
            "Time taken 0:02:46.139736\n",
            "\n",
            "Epoch 16 Loss 233.6890\n",
            "Time taken 0:02:46.286823\n",
            "\n",
            "Epoch 17 Loss 231.6549\n",
            "Time taken 0:02:46.445390\n",
            "\n",
            "Epoch 18 Loss 229.4175\n",
            "Time taken 0:02:46.103484\n",
            "\n",
            "Epoch 19 Loss 227.5420\n",
            "Time taken 0:02:46.088770\n",
            "\n",
            "Epoch 20 Loss 225.6653\n",
            "Time taken 0:02:46.510555\n",
            "\n",
            "Epoch 21 Loss 223.6823\n",
            "Time taken 0:02:46.634816\n",
            "\n",
            "Epoch 22 Loss 221.6923\n",
            "Time taken 0:02:46.649617\n",
            "\n",
            "Epoch 23 Loss 219.8182\n",
            "Time taken 0:02:46.441504\n",
            "\n",
            "Epoch 24 Loss 218.0512\n",
            "Time taken 0:02:46.439710\n",
            "\n",
            "Epoch 25 Loss 216.3117\n",
            "Time taken 0:02:46.545828\n",
            "\n",
            "Epoch 26 Loss 214.7344\n",
            "Time taken 0:02:46.200952\n",
            "\n",
            "Epoch 27 Loss 213.2016\n",
            "Time taken 0:02:46.508165\n",
            "\n",
            "Epoch 28 Loss 211.5055\n",
            "Time taken 0:02:45.866615\n",
            "\n",
            "Epoch 29 Loss 209.8619\n",
            "Time taken 0:02:45.904746\n",
            "\n",
            "Epoch 30 Loss 208.2738\n",
            "Time taken 0:02:45.704130\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEr2AFkJMOUB"
      },
      "source": [
        "def evaluate(data):\n",
        "    loss = 0\n",
        "    results = []\n",
        "    bleu = 0\n",
        "\n",
        "    for i, (inpt, prime, y) in enumerate(data):\n",
        "\n",
        "        result = '<start>'\n",
        "        next_word = True\n",
        "\n",
        "        init_state = None\n",
        "        \n",
        "        enc_output, hidden = encoder(inpt, \n",
        "                                     init_state)\n",
        "        prime_output, hidden_prime = encoder_prime(prime, \n",
        "                                                   init_state)\n",
        "\n",
        "        # This feeds in the start token for the first initial state\n",
        "        dec_input = tf.expand_dims([target_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "\n",
        "        dec_hidden_forward = tf.zeros((1, ENCODER_UNITS))\n",
        "\n",
        "        j = 1  # iterative count\n",
        "        while next_word: \n",
        "            # dec_hidden shape: (batch_size, decoder_units)\n",
        "            # dec_input shape: (batch_size, 1)\n",
        "            predictions, dec_hidden_forward = decoder(dec_input, hidden, \n",
        "                                                      hidden_prime, enc_output, \n",
        "                                                      prime_output, \n",
        "                                                      dec_hidden_forward)\n",
        "                                                         \n",
        "            loss += loss_function(y[:, j], predictions)\n",
        "            \n",
        "            # max logit for tokenized word\n",
        "            word_idx = tf.argmax(predictions[0]).numpy()\n",
        "            word = target_tokenizer.index_word[word_idx]\n",
        "            result += word + ' '\n",
        "\n",
        "            dec_input = tf.expand_dims([word_idx], 0)\n",
        "\n",
        "            if word == '<end>':\n",
        "                next_word = False\n",
        "            \n",
        "            if j >= y.shape[1] - 1:\n",
        "                result += '<end>'\n",
        "                next_word = False\n",
        "            \n",
        "            j += 1\n",
        "\n",
        "        results.append(result)\n",
        "        bleu += sentence_bleu(f_holdout[i], result)\n",
        "\n",
        "    return results, loss.numpy() / len(f_holdout), bleu / len(f_holdout)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vft0SHsNEBNk",
        "outputId": "8d6f42ad-0565-46e8-e6bf-e226d973bc94"
      },
      "source": [
        "results, test_loss, bleu = evaluate(test)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7UPBTU-aZiY",
        "outputId": "64b9b48f-5554-4cd5-8307-2ad6727e7eda"
      },
      "source": [
        "bleu"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7734854206757209"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKq-oauPgYLW",
        "outputId": "a8f7dc89-b8c8-480a-f20e-c9a3e4ff0dd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_loss"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51.366802291987675"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RXdV1DNZqAj"
      },
      "source": [
        "def examine(index):\n",
        "    print(\"Informal: \", if_holdout[index])\n",
        "    print(\"Formal: \", f_holdout[index])\n",
        "    print(\"Predicted: \", results[index])"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNS9wCEOaOmH",
        "outputId": "7644edb0-a8a9-4041-d104-0863424cfa36"
      },
      "source": [
        "examine(1300)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Informal:  <start> I have a few I picked up in a New & Used bookstore near me .  <end>\n",
            "Formal:  <start> I own a few that I found at a new and used bookstore near me .  <end>\n",
            "Predicted:  <start>I a years years years years years years years years years years years years years years years years years years years years years years years years years years years years years years years <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvOX0GHmq829"
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ou7Rzhd6x2d"
      },
      "source": [
        "with open(BASE_PATH + '/Results/HA_results.txt', 'w') as f:\n",
        "    for seq in results:\n",
        "        f.write(seq + '\\n')"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd6Tdsingu7W"
      },
      "source": [
        "encoder.save_weights(BASE_PATH + '/Model Weights/Rule-Assisted/encoder')\n",
        "encoder_prime.save_weights(BASE_PATH + '/Model Weights/Rule-Assisted/encoder_prime')\n",
        "decoder.save_weights(BASE_PATH + '/Model Weights/Rule-Assisted/decoder')"
      ],
      "execution_count": 116,
      "outputs": []
    }
  ]
}