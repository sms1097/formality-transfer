{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "HA Rules.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAbxrR_Q1v3m"
      },
      "source": [
        "# Hierarchal Encoding with Rules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZpo0DbmMOT_"
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "import re \n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIh8TGdFMOT_"
      },
      "source": [
        "### Declare Static Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLWD_vDUMUbK",
        "outputId": "1a2a00ac-16ca-4f76-acbe-855ffad790f3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiCo7jwJMOT_"
      },
      "source": [
        "These parameters are mostly stolen from the Google Paper, except for embedding dim which is determined from GloVE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgjKj15QMOT_"
      },
      "source": [
        "EMBEDDING_DIM = 200\n",
        "ATTENTION_UNITS = 512\n",
        "ENCODER_UNITS = 1024\n",
        "DECODER_UNITS = 1024\n",
        "BATCH_SIZE = 64\n",
        "MAX_INPUT_LENGTH = 32"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9sTDg2lMOT_"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzSYxc4yMOT_"
      },
      "source": [
        "BASE_PATH = '/content/drive/MyDrive/Data/Data'  # on local is path to directory\n",
        "# BASE_PATH = '../../Data'\n",
        "\n",
        "FORMAL_PATH_TRAIN = '{}/Supervised Data/Entertainment_Music/S_Formal_EM_Train.txt'.format(BASE_PATH)\n",
        "INFORMAL_PATH_TRAIN = '{}/Supervised Data/Entertainment_Music/S_Informal_EM_Train.txt'.format(BASE_PATH)\n",
        "\n",
        "FORMAL_PATH_HOLDOUT = '{}/Supervised Data/Entertainment_Music/S_Formal_EM_ValTest.txt'.format(BASE_PATH)\n",
        "INFORMAL_PATH_HOLDOUT = '{}/Supervised Data/Entertainment_Music/S_Informal_EM_ValTest.txt'.format(BASE_PATH)\n",
        "\n",
        "CONTRACTIONS_PATH = '{}/Rule Data/Contractions.txt'.format(BASE_PATH)\n",
        "SLANG_PATH = '{}/Rule Data/Slang.txt'.format(BASE_PATH)\n",
        "SWEARS_PATH = '{}/Rule Data/Swears.csv'.format(BASE_PATH)\n",
        "\n",
        "EMBEDDING_PATH = '{}/glove.6B.200d.txt'.format(BASE_PATH)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6EaDkEtMOUA"
      },
      "source": [
        "formal = open(FORMAL_PATH_TRAIN).read()\n",
        "informal = open(INFORMAL_PATH_TRAIN).read()\n",
        "\n",
        "formal_holdout = open(FORMAL_PATH_HOLDOUT).read()\n",
        "informal_holdout = open(INFORMAL_PATH_HOLDOUT).read()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fenTZWMxMOUA"
      },
      "source": [
        "def process_sequence(seq):\n",
        "    \"\"\"This inserts a space in between the last word and a period\"\"\"\n",
        "    s = re.sub('([.,!?()])', r' \\1 ', seq)\n",
        "    s = re.sub('\\s{2,}', ' ', s)\n",
        "    \n",
        "    return '<start> ' + s + ' <end>'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_pLPgB0MOUA"
      },
      "source": [
        "f_corpus = [process_sequence(seq) for seq in formal.split('\\n')]\n",
        "if_corpus = [process_sequence(seq) for seq in informal.split('\\n')]\n",
        "\n",
        "f_holdout = [process_sequence(seq) for seq in formal_holdout.split('\\n')]\n",
        "if_holdout = [process_sequence(seq) for seq in informal_holdout.split('\\n')]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkN39M_qck6K"
      },
      "source": [
        "### Load slang and Contractions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC7iHUueck6K"
      },
      "source": [
        "import csv\n",
        "cont = []\n",
        "cont_corr = []\n",
        "\n",
        "slang = []\n",
        "slang_corr = []\n",
        "\n",
        "swears = []\n",
        "with open(CONTRACTIONS_PATH, 'r') as f:\n",
        "    for line in csv.reader(f, dialect='excel-tab'):\n",
        "        cont.append(line[0])\n",
        "        cont_corr.append(line[1])\n",
        "        \n",
        "with open(SLANG_PATH) as f:\n",
        "    for line in csv.reader(f, dialect='excel-tab'):\n",
        "        slang.append(line[0])\n",
        "        slang_corr.append(line[1])\n",
        "        \n",
        "with open(SWEARS_PATH) as f:\n",
        "    for line in csv.reader(f):\n",
        "        swears.append(line)\n",
        "swears = swears[0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ55lZV3ck6K"
      },
      "source": [
        "### Apply Rules\n",
        "1. Capitalize the first word\n",
        "2. Lowercase words that are all upper case\n",
        "3. Expand contractions\n",
        "4. Replace Slang words\n",
        "5. Replace Swear words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXTFzrX_ck6K"
      },
      "source": [
        "def rule(seqs):\n",
        "    out = []\n",
        "    for seq in seqs:\n",
        "        curr_seq = seq.split()\n",
        "        temp = []\n",
        "        \n",
        "        for i, word in enumerate(curr_seq):\n",
        "            curr_word = word\n",
        "            \n",
        "            if i == 1:\n",
        "                curr_word = curr_word.capitalize()\n",
        "            \n",
        "            if curr_word == curr_word.upper():\n",
        "                curr_word = curr_word.lower()\n",
        "                \n",
        "            if curr_word in slang:\n",
        "                curr_word = slang_corr[slang.index(curr_word)]\n",
        "                \n",
        "            if curr_word in swears:\n",
        "                curr_word = curr_word[0] + '*' * (len(curr_word) - 2)\n",
        "            \n",
        "            temp.append(curr_word)\n",
        "                \n",
        "        out.append(' '.join(temp))  \n",
        "    return out"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCrQj9dxck6K"
      },
      "source": [
        "x_prime_raw = rule(if_corpus)\n",
        "x_prime_holdout = rule(if_holdout)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuet6JWVMOUA"
      },
      "source": [
        "### Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czog7VXRMOUA"
      },
      "source": [
        "def tokenize(corpus, tokenizer=None, maxlen=None):\n",
        "    \"\"\" Tokenize data and pad sequences \"\"\"\n",
        "    if not tokenizer: \n",
        "        tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', \n",
        "                              oov_token='<OOV>', lower=False)\n",
        "        tokenizer.fit_on_texts(corpus)\n",
        "    \n",
        "    seqs = tokenizer.texts_to_sequences(corpus)\n",
        "    padded_seqs = pad_sequences(seqs, padding='post', maxlen=maxlen)\n",
        "\n",
        "    return padded_seqs, tokenizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8gCiXWAMOUA"
      },
      "source": [
        "input_train, input_tokenizer = tokenize(if_corpus)\n",
        "input_prime, _ = tokenize(x_prime_raw, input_tokenizer)\n",
        "target_train, target_tokenizer = tokenize(f_corpus)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROQQKO8uMOUA"
      },
      "source": [
        "input_test, _ = tokenize(if_holdout, input_tokenizer)\n",
        "prime_test, _ = tokenize(x_prime_holdout, input_tokenizer)\n",
        "target_test, _ = tokenize(f_holdout, target_tokenizer)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJpBO_F9MOUA"
      },
      "source": [
        "buffer_size = len(input_train)\n",
        "steps_per_epoch = len(input_train) // BATCH_SIZE\n",
        "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
        "\n",
        "train = tf.data.Dataset.from_tensor_slices((input_train, input_prime, target_train)).shuffle(buffer_size)\n",
        "train = train.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "test = tf.data.Dataset.from_tensor_slices((input_test, prime_test, target_test)).batch(1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua_l1fZEMOUA"
      },
      "source": [
        "example_input_batch, example_prime_batch, example_target_batch = next(iter(train))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSCRTB5PjmvD"
      },
      "source": [
        "# Setup Embedding Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enju-_z_p9u7"
      },
      "source": [
        "def embedding_matrix(tokenizer, vocab_size, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(EMBEDDING_PATH) as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "\n",
        "    embeddings_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in tokenizer.word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embeddings_matrix[i] = embedding_vector\n",
        "\n",
        "    return embeddings_matrix"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovQqc3ibqVj6"
      },
      "source": [
        "enc_E_mat = embedding_matrix(input_tokenizer, input_vocab_size, EMBEDDING_DIM)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pv7RI8NMOUA"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dVMrge8kBd3"
      },
      "source": [
        "Using one bidirectional LSTMs because that was reported to get almost as good performance as 2 LSTMs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiW3IKWKMOUA"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, encoder_units, weight_matrix):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, \n",
        "                                                   embedding_dim,\n",
        "                                                   weights=[weight_matrix])\n",
        "        self.lstm_1 = tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.LSTM(\n",
        "                encoder_units,\n",
        "                return_sequences=True,\n",
        "                return_state=True,\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
        "                recurrent_regularizer=tf.keras.regularizers.l2(0.01),\n",
        "                bias_regularizer=tf.keras.regularizers.l2(0.01)\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def call(self, x, hidden_state):\n",
        "        \"\"\"Shove into latent space\"\"\"\n",
        "        # x shape: (batch_size x max_length x embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # output shape: (batch_size x max_length x 2 * encoder_units)\n",
        "        # h_f, h_b shapes: (batch_size x encoder_units)\n",
        "        output, h_f, _, h_b, _ = self.lstm_1(x, initial_state=hidden_state)\n",
        "\n",
        "        return output, h_f, h_b"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWA8hQqD1v3n"
      },
      "source": [
        "encoder = Encoder(input_vocab_size, EMBEDDING_DIM, ENCODER_UNITS, enc_E_mat)\n",
        "\n",
        "encoder_prime = Encoder(input_vocab_size, EMBEDDING_DIM, ENCODER_UNITS, enc_E_mat)\n",
        "\n",
        "init_state = [tf.zeros((BATCH_SIZE, ENCODER_UNITS)) for _ in range(4)]\n",
        "\n",
        "sample_output, enc_hidden_forward, enc_hidden_backward = encoder(example_input_batch, init_state)\n",
        "prime_output, prime_hidden_forward, prime_hidden_backward = encoder_prime(example_prime_batch, init_state)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDWvnXwd-pQy"
      },
      "source": [
        "## Combined Encoders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSSXJ0c3-eTn"
      },
      "source": [
        "class CombinedEncoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, encoder_units, weight_matrix):\n",
        "        super(CombinedEncoder, self).__init__()\n",
        "        self.seq_encoder = Encoder(input_vocab_size, EMBEDDING_DIM, ENCODER_UNITS, enc_E_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc0BAr9pMOUA"
      },
      "source": [
        "### Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP5YEjIOMOUA"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    This is different form the Luong paper since it \n",
        "    concatenates the forward and backward hidden states\n",
        "    to caculate attention\n",
        "    \"\"\"\n",
        "    def __init__(self, units):\n",
        "        \"\"\"These parameters follow notation from Bahdanau paper\"\"\"\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W = tf.keras.layers.Dense(units)\n",
        "        self.U = tf.keras.layers.Dense(units)\n",
        "        self.v = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, enc_opt, hidden_f, hidden_b):\n",
        "        # concatenate hidden states as in eq 7 Bahdanau\n",
        "        # hidden shape: (batch_size, 2 * lstm_units)\n",
        "        hidden = tf.concat([hidden_f, hidden_b], axis=-1)\n",
        "\n",
        "        # expand dims to meet shape of latent tensor\n",
        "        # hidden_broad shape: (batch_size, 1, encoder_units * 2)\n",
        "        hidden_broad = tf.expand_dims(hidden, 1)\n",
        "\n",
        "        # Alignment model score from A.1.2 of Bahdanau et al \n",
        "        # score shape: (batch_size, max_length, v_units)\n",
        "        score = self.v(tf.nn.tanh(self.W(hidden_broad) + self.U(enc_opt)))\n",
        "\n",
        "        # softmax generalization of eq(7) Luong\n",
        "        # attention_weights shape: (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)  \n",
        "\n",
        "        # This takes weighted average with attention weights\n",
        "        # context shape: (batch_size, 2 * encoder_units)\n",
        "        context = attention_weights * enc_opt\n",
        "        context = tf.reduce_sum(context, axis=1)\n",
        "\n",
        "        return context"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBwfe07qMOUA"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-RvXiF1MOUA"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, attention_units, \n",
        "                 decoder_units):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.attention = BahdanauAttention(attention_units)\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm_1 = tf.keras.layers.LSTM(decoder_units,\n",
        "                                           return_sequences=True,\n",
        "                                           return_state=True)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.opt = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, x, hidden_f, hidden_b, encoder_output):\n",
        "        context_vector = self.attention(encoder_output, hidden_f, hidden_b)\n",
        "\n",
        "        # x shape: (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # x shape: (batch_size, 1, embedding_dim + 2 * encoder_units)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "        # output shape: (batch_size, 1, decoder_units)\n",
        "        # this shape is only important for expanding decoder depth\n",
        "        output, h_f, c_f = self.lstm_1(x)\n",
        "\n",
        "        # flatten to feed into opt\n",
        "        # output shape: (batch_size, hidden_size)\n",
        "        output = self.flatten(output)\n",
        "\n",
        "        # get logits\n",
        "        # x shape: (batch_size, vocab)\n",
        "        x = self.opt(output)\n",
        "\n",
        "        return x, h_f"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHUOKBZj1v3n"
      },
      "source": [
        "seq_decoder = Decoder(target_vocab_size, EMBEDDING_DIM, ATTENTION_UNITS, DECODER_UNITS)\n",
        "prime_decoder = Decoder(target_vocab_size, EMBEDDING_DIM, ATTENTION_UNITS, DECODER_UNITS)\n",
        "\n",
        "sample_decoder_input = tf.expand_dims([target_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "dec_hidden_forward = tf.zeros((64, ENCODER_UNITS))\n",
        "\n",
        "seq_decoder_out, seq_decoder_hidden = seq_decoder(sample_decoder_input, enc_hidden_forward, \n",
        "                                                  enc_hidden_backward, sample_output)\n",
        "prime_decoder_out, prime_decoder_hidden = prime_decoder(sample_decoder_input, prime_hidden_forward, \n",
        "                                                        prime_hidden_backward, prime_output)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjwpAaWZ1v3n"
      },
      "source": [
        "## Hierarchal Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwcAlJ8Q1v3n"
      },
      "source": [
        "class CombinedDecoders(tf.keras.Model): \n",
        "    def __init__(self, input_vocab_size, target_vocab_size, embedding_dim,  \n",
        "                 attention_units, encoder_units, decoder_units, embedding_weights): \n",
        "        super(CombinedDecoders, self).__init__()\n",
        "        \n",
        "        # declare decoders\n",
        "        self.seq_decoder = Decoder(target_vocab_size, embedding_dim, attention_units, decoder_units)\n",
        "        self.prime_decoder = Decoder(target_vocab_size, embedding_dim, attention_units, decoder_units)\n",
        "        \n",
        "        # create weights\n",
        "        self.W = tf.keras.layers.Dense(target_vocab_size)\n",
        "        \n",
        "    def call(self, dec_input, seq_enc_out, seq_enc_forward, seq_enc_backward,\n",
        "             prime_enc_out, prime_enc_forward, prime_enc_backward):\n",
        "        \n",
        "        seq_decoder_out, seq_decoder_forward = self.seq_decoder(dec_input, seq_enc_forward,\n",
        "                                                               seq_enc_backward, seq_enc_out)\n",
        "        prime_decoder_out, prime_decoder_forward = self.prime_decoder(dec_input, prime_enc_forward, \n",
        "                                                                     prime_enc_backward, prime_enc_out)\n",
        "        \n",
        "        # Now do Hierarchal attention\n",
        "        # adaptation of eq (3) form Wang et al. \n",
        "        alpha = tf.exp(self.W(seq_decoder_out)) / (tf.exp(self.W(seq_decoder_out)) + tf.exp(self.W(prime_decoder_out)))\n",
        "        beta = 1 - alpha\n",
        "        \n",
        "        return alpha * seq_decoder_out + beta * prime_decoder_out, seq_decoder_forward, prime_decoder_forward"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r-mcXOu1v3n"
      },
      "source": [
        "ha_decoder = CombinedDecoders(input_vocab_size, target_vocab_size, EMBEDDING_DIM,\n",
        "                              ATTENTION_UNITS, ENCODER_UNITS, DECODER_UNITS, enc_E_mat)\n",
        "\n",
        "sample_decoder_input = tf.expand_dims([target_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "dec_hidden_forward = tf.zeros((64, ENCODER_UNITS))\n",
        "\n",
        "seq_decoder_out, seq_decoder_hidden = seq_decoder(sample_decoder_input, enc_hidden_forward, \n",
        "                                                  enc_hidden_backward, sample_output)\n",
        "prime_decoder_out, prime_decoder_hidden = prime_decoder(sample_decoder_input, prime_hidden_forward, \n",
        "                                                        prime_hidden_backward, prime_output)\n",
        "\n",
        "sample_prediciton, seq_dec_foward, prime_dec_forward = ha_decoder(sample_decoder_input, sample_output,\n",
        "                                                                  enc_hidden_forward, enc_hidden_backward, \n",
        "                                                                  prime_output, prime_hidden_forward, \n",
        "                                                                  prime_hidden_backward)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0P04Qa_MOUA"
      },
      "source": [
        "### Optimizer and Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unPfCctsMOUA"
      },
      "source": [
        "Here we define the optimizer and the loss function. In our loss function we mask the zeros since that's the padding.\n",
        "\n",
        "Also of note is in the loss function. The reduction argument at default does some really wonky things which threw off all results. Had to change the reduciton to none, which at default is auto. Not exactly sure what it does in this context but it tries to sum over batches. I didn't work with it because I wanted to control all loss calculation manually. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kis6sBiBMOUA"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "static_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnIepemQMOUA"
      },
      "source": [
        "def loss_function(real, preds):\n",
        "    \"\"\"Calculate and return loss\"\"\"\n",
        "\n",
        "    # caclulate loss\n",
        "    loss = static_loss(real, preds)\n",
        "    \n",
        "    # create padding mask \n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    \n",
        "    # apply mask\n",
        "    loss *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lzJ5Y0gMOUB"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOLvx7ygrMtv"
      },
      "source": [
        "This is the training loop. I'm using teacher forcing because I don't think I have enough computational power to use beam search. Google reccomends beam search with a beam width of 10, but that isn't an option here. Teacher forcing will provide better results than without using it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV21GU90MOUB"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inpt, prime, trgt, init_state):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        seq_enc_out, seq_enc_forward, seq_enc_backward = seq_encoder(inpt, hidden_state=init_state)\n",
        "        prime_enc_out, prime_enc_forward, prime_enc_backward = prime_encoder(prime, hidden_state=init_state)\n",
        "\n",
        "        # Get start token for every sequence in batch\n",
        "        dec_input = tf.expand_dims([target_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "        \n",
        "        # initialize decoder hidden forward states\n",
        "        seq_dec_forward = seq_enc_forward\n",
        "        prime_dec_forward = prime_enc_forward\n",
        "        \n",
        "        for i in range(1, trgt.shape[1]):\n",
        "            # dec_hidden shape: (batch_size, decoder_units)\n",
        "            # dec_input shape: (batch_size, 1)\n",
        "            prediction, seq_dec_foward, prime_dec_forward = ha_decoder(dec_input, \n",
        "                                                                       seq_enc_out,\n",
        "                                                                       seq_dec_forward, \n",
        "                                                                       enc_hidden_backward, \n",
        "                                                                       prime_output, \n",
        "                                                                       prime_enc_forward, \n",
        "                                                                       prime_hidden_backward)\n",
        "\n",
        "            loss += loss_function(trgt[:, i], prediction)\n",
        "            dec_input = tf.expand_dims(trgt[:, i], 1)\n",
        "\n",
        "        # Apply gradients \n",
        "        trainable_variables = prime_encoder.trainable_variables + seq_encoder.trainable_variables  + ha_decoder.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "\n",
        "        # return batch loss\n",
        "        return loss"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iXRvBFyOMOUB",
        "outputId": "f7ef5295-47d9-4cc9-e809-3a57b02f2ced"
      },
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "seq_encoder = Encoder(input_vocab_size, EMBEDDING_DIM, ENCODER_UNITS, enc_E_mat)\n",
        "prime_encoder = Encoder(input_vocab_size, EMBEDDING_DIM, ENCODER_UNITS, enc_E_mat)\n",
        "ha_decoder = CombinedDecoders(input_vocab_size, target_vocab_size, EMBEDDING_DIM,\n",
        "                              ATTENTION_UNITS, ENCODER_UNITS, DECODER_UNITS, enc_E_mat)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = datetime.now()\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    # This resets the hidden state of the LSTM for every epoch\n",
        "    init_state = [tf.zeros((BATCH_SIZE, ENCODER_UNITS)) for _ in range(4)]\n",
        "\n",
        "    for inpt, prime, trgt in train.take(steps_per_epoch):\n",
        "        total_loss += train_step(inpt, prime, trgt, init_state)\n",
        "\n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                        total_loss / BATCH_SIZE))\n",
        "    print('Time taken {}\\n'.format(datetime.now() - start))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['encoder_13/bidirectional_13/backward_lstm_33/lstm_cell_61/kernel:0', 'encoder_13/bidirectional_13/backward_lstm_33/lstm_cell_61/recurrent_kernel:0', 'encoder_13/bidirectional_13/backward_lstm_33/lstm_cell_61/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['encoder_13/bidirectional_13/backward_lstm_33/lstm_cell_61/kernel:0', 'encoder_13/bidirectional_13/backward_lstm_33/lstm_cell_61/recurrent_kernel:0', 'encoder_13/bidirectional_13/backward_lstm_33/lstm_cell_61/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-7397d6abe69d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[19740,19740] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/combined_decoders_9/dense_97/MatMul_119 (defined at <ipython-input-44-47dc67f1f52c>:32) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[gradient_tape/encoder_13/embedding_33/embedding_lookup/Reshape/_446]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[19740,19740] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/combined_decoders_9/dense_97/MatMul_119 (defined at <ipython-input-44-47dc67f1f52c>:32) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_step_521012]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/combined_decoders_9/dense_97/MatMul_119:\n combined_decoders_9/decoder_20/dense_92/BiasAdd_22 (defined at <ipython-input-21-829fe19151d8>:33)\n\nInput Source operations connected to node gradient_tape/combined_decoders_9/dense_97/MatMul_119:\n combined_decoders_9/decoder_20/dense_92/BiasAdd_22 (defined at <ipython-input-21-829fe19151d8>:33)\n\nFunction call stack:\ntrain_step -> train_step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEr2AFkJMOUB"
      },
      "source": [
        "def evaluate(data):\n",
        "    loss = 0\n",
        "    results = []\n",
        "    bleu = 0\n",
        "\n",
        "    for i, (x, y) in enumerate(data):\n",
        "\n",
        "        result = '<start> '\n",
        "        next_word = True\n",
        "\n",
        "        init_state = [tf.zeros((1, ENCODER_UNITS)) for _ in range(4)]\n",
        "\n",
        "        # This feeds in the start token for the first initial state\n",
        "        dec_input = tf.expand_dims([target_tokenizer.word_index['<start>']], 0)\n",
        "        \n",
        "        # Get inputs\n",
        "        enc_output, dec_hidden_forward, dec_hidden_backward = encoder(x, None)\n",
        "\n",
        "        i = 1  # iterative count\n",
        "        while next_word: \n",
        "            # dec_hidden shape: (batch_size, decoder_units)\n",
        "            # dec_input shape: (batch_size, 1)\n",
        "            predictions, dec_hidden_forward, _ = decoder(dec_input, \n",
        "                                                         dec_hidden_forward, \n",
        "                                                         dec_hidden_backward, \n",
        "                                                         enc_output)\n",
        "\n",
        "            loss += loss_function(y[:, i], predictions)\n",
        "            \n",
        "            # max logit for tokenized word\n",
        "            word_idx = tf.argmax(predictions[0]).numpy()\n",
        "            word = target_tokenizer.index_word[word_idx]\n",
        "            result += word + ' '\n",
        "\n",
        "            dec_input = tf.expand_dims([word_idx], 0)\n",
        "\n",
        "            if word == '<end>':\n",
        "                next_word = False\n",
        "            \n",
        "            if i >= y.shape[1] - 1:\n",
        "                result += '<end>'\n",
        "                next_word = False\n",
        "            \n",
        "            i += 1\n",
        "\n",
        "        results.append(result)\n",
        "\n",
        "    return results, loss.numpy() / len(f_holdout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vft0SHsNEBNk"
      },
      "source": [
        "results, test_loss = evaluate(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RXdV1DNZqAj"
      },
      "source": [
        "def examine(index):\n",
        "    print(\"Informal: \", if_holdout[index])\n",
        "    print(\"Formal: \", f_holdout[index])\n",
        "    print(\"Predicted: \", results[index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNS9wCEOaOmH"
      },
      "source": [
        "examine(1999)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmPUxI3MPl1J"
      },
      "source": [
        "with open(BASE_PATH + '/Results/Bahdanau_Attention_Results_Custom.txt', 'w') as f:\n",
        "    for seq in results:\n",
        "        f.write(seq + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}